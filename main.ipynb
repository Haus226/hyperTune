{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Implement parameter wrapper classes"]},{"cell_type":"code","execution_count":138,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T00:20:20.722662Z","iopub.status.busy":"2024-05-24T00:20:20.722287Z","iopub.status.idle":"2024-05-24T00:20:20.737580Z","shell.execute_reply":"2024-05-24T00:20:20.736595Z","shell.execute_reply.started":"2024-05-24T00:20:20.722632Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting paramsSpace.py\n"]}],"source":["%%writefile paramsSpace.py\n","\n","from typing import Iterable\n","import numpy as np\n","\n","'''\n","Class to wrap Real, Integer, Categorical hyperparameter\n","'''\n","class Real:\n","    def __init__(self, low, high) -> None:\n","        self.__low = low\n","        self.__high = high\n","    \n","    def sample(self, shape):\n","        s = np.random.uniform(self.__low, self.__high, size=shape)\n","        return s\n","    \n","    def interval(self):\n","        return np.array([self.__low, self.__high])\n","    \n","class Int:\n","    def __init__(self, low, high) -> None:\n","        self.__low = low\n","        self.__high = high\n","\n","    def sample(self, shape):\n","        s = np.random.randint(self.__low, self.__high + 1, size=shape)\n","        return s\n","    \n","    def interval(self):\n","        return np.array([self.__low, self.__high])\n","\n","class Cat:\n","    def __init__(self, category:Iterable) -> None:\n","        self.category = category\n","\n","    def sample(self, shape):\n","        s = np.random.randint(0, len(self.category), size=shape)\n","        return s\n","    \n","    def interval(self):\n","        return np.array([0, len(self.category) - 1])\n","\n","class Choice:\n","    def __init__(self, choice:Iterable) -> None:\n","        self.choice = choice\n","\n","    def sample(self, shape):\n","        s = np.random.choice(self.choice, size=shape, replace=True)\n","        return s\n","    \n","    def interval(self):\n","        return np.array([0, len(self.choice) - 1])\n","\n","class RealKernels:\n","    '''\n","    Class to wrap hyperparameter for Gaussian Process Regressor kernel\n","    '''\n","    def __init__(self, bounds:np.array) -> None:\n","        self.__bounds = bounds\n","\n","    def sample(self, shape):\n","        s = np.random.uniform(self.__bounds[:, 0], self.__bounds[:, 1], size=shape)\n","        return s\n","\n","    def interval(self):\n","        return self.__bounds\n","\n","class AcqParams:\n","    '''\n","    Class to wrap hyperparameter so that \n","    it can be passed into acquisition function\n","    '''\n","    def __init__(self, params) -> None:\n","        self.__params = params\n","\n","    def sample(self, shape):\n","        s = np.zeros(shape)\n","        for idx, p in enumerate(self.__params):\n","            s[:, idx] = self.__params[p].sample(shape[0])\n","        return s\n","\n","    def interval(self):\n","        bounds = np.zeros((len(self.__params), 2))\n","        for idx, p in enumerate(self.__params):\n","            bounds[idx] = self.__params[p].interval()\n","        return bounds\n","    \n","    def Int_idxs(self):\n","        mask_int = []\n","        for idx, p in enumerate(self.__params):\n","            if type(self.__params[p]) == Int: \n","                mask_int.append(idx)\n","        mask_int = np.array(mask_int)\n","        return mask_int\n","    \n","    def Cat_idxs(self):\n","        mask_cat = []\n","        for idx, p in enumerate(self.__params):\n","            if type(self.__params[p]) == Cat: \n","                mask_cat.append(idx)\n","        mask_cat = np.array(mask_cat)\n","        return mask_cat\n","\n","\n","\n","\n","def convert_to_bound(params:dict) -> np.array:\n","    '''\n","    Convert hyperparameter dictionary into numpy array bounds\n","    '''\n","    if \"theta\" in params:\n","        bound = params[\"theta\"].interval()\n","    elif \"x\" in params:\n","        bound = params[\"x\"].interval()\n","    else:\n","        bound = np.zeros(shape=(len(params), 2))\n","        for idx, p in enumerate(params):\n","            bound[idx] = params[p].interval()\n","    return bound\n","\n","def decode_acq_params(encoded, params):\n","    '''\n","    Decode the encoded acquisition data back to \n","    hyperparameter dictionary\n","    '''\n","    params_ = {}\n","    for idx, p in enumerate(params):\n","        if type(params[p]) == Int:\n","            params_[p] = encoded[\"x\"][idx].astype(int)\n","        elif type(params[p]) == Cat:\n","            params_[p] = params[p].category[encoded[\"x\"][idx].astype(int)]\n","        elif type(params[p]) == Real:\n","            params_[p] = encoded[\"x\"][idx]\n","    return params_\n","\n","def convert_to_params(encoded, params):\n","    '''\n","    Convert the numpy array (encoded hyperparameter) to\n","    hyperparameter dictionary\n","    '''\n","    params_ = {}\n","    # print(encoded)\n","    if \"theta\" in params:\n","        params_[\"theta\"] = encoded\n","        return params_\n","    elif \"x\" in params:\n","        params_[\"x\"] = encoded\n","        return params_\n","    for idx, p in enumerate(params):\n","        if type(params[p]) == Real:\n","            params_[p] = encoded[idx]\n","        elif type(params[p]) == Int:\n","            params_[p] = encoded[idx].astype(int)\n","        elif type(params[p]) == Cat:\n","            params_[p] = params[p].category[encoded[idx].astype(int)]\n","    return params_\n","            \n","    \n","\n","if __name__ == \"__main__\":\n","    from keras.layers import Dense, Conv2D\n","    params = {\n","        \"Layer1\":Cat([Dense, Conv2D]),\n","        \"Layer1_filters\":Cat([8, 16, 32]),\n","        \"Layer1_kernel_size\":Cat([3, 5, 7]),\n","        \"Layer1_units\":Int(12, 64),\n","        \"Layer1_activation\":Cat([\"relu\", \"sigmoid\"]),\n","\n","        \"Layer2_units\":Int(32, 128),\n","        \"Layer2_activation\":Cat([\"relu\", \"sigmoid\"]),\n","        \"optimizer\":Cat([\"adam\", \"sgd\", \"rmsprop\"]),\n","        \"epochs\":Int(5, 20),\n","        \"batch_size\":Int(64, 256),\n","        \"learning_rate\":Real(0.0001, 0.01)\n","    }"]},{"cell_type":"markdown","metadata":{},"source":["# Utils"]},{"cell_type":"code","execution_count":139,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T00:20:20.744791Z","iopub.status.busy":"2024-05-24T00:20:20.744287Z","iopub.status.idle":"2024-05-24T00:20:20.755439Z","shell.execute_reply":"2024-05-24T00:20:20.754473Z","shell.execute_reply.started":"2024-05-24T00:20:20.744754Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting util.py\n"]}],"source":["%%writefile util.py\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","# import seaborn as sns\n","import pandas as pd\n","from paramsSpace import convert_to_params\n","\n","def plot1D(x, f, opt, n_samples, label):\n","    X = x.reshape(-1, 1)\n","    y = [f(x_) for x_ in x]\n","    if hasattr(opt, \"_gp\"):\n","        model = opt._gp\n","    elif hasattr(opt, \"gp\"):\n","        model = opt.gp\n","\n","    if hasattr(opt, \"x_history\") and hasattr(opt, \"y_history\"):\n","        plt.scatter(opt.x_history, opt.y_history, c=\"blue\", s=100, marker=\"+\")\n","\n","    mean, std = model.predict(X, return_std=True)\n","\n","    y_samples = model.sample_y(X, n_samples)\n","    for idx, single_prior in enumerate(y_samples.T):\n","        # print(\"Single Prior : \", single_prior)\n","        plt.plot(\n","            x,\n","            single_prior.reshape(x.shape[0]),\n","            linestyle=\"--\",\n","            alpha=0.7,\n","            label=f\"Sampled function #{idx + 1}\",\n","        )\n","    plt.plot(x, mean, label=label)\n","    plt.plot(x, y, label=\"Actual\")\n","    plt.fill_between(\n","        x,\n","        mean.reshape(x.shape[0], ) - std,\n","        mean.reshape(x.shape[0], ) + std,\n","        alpha=0.1,\n","        label=fr\"{label} mean $\\pm$ 1 std. dev.\",\n","    )\n","    if hasattr(opt, \"x_history\") and hasattr(opt, \"y_history\"):\n","        plt.scatter(opt.x_history, opt.y_history, c=\"blue\", s=100, marker=\"+\")\n","\n","    plt.legend()\n","    # plt.show()\n","\n","def plot2D(x, y, f, opt):\n","    x_, y_ = np.meshgrid(x, y)\n","    # z = f(x_, y_)\n","    z = np.zeros_like(x_)\n","    for idx in range(x_.shape[0]):\n","        for jdx in range(x_.shape[1]):\n","            z[idx, jdx] = f(x_[idx][jdx], y_[idx][jdx])\n","    print(z.max())\n","    fig, axs = plt.subplots(ncols=3)\n","    \n","    c_actual = axs[0].contourf(x_, y_, z, levels=100, cmap=\"viridis\")\n","    axs[0].set_title(\"Actual\")\n","    axs[0].grid()\n","    axs[0].plot()\n","\n","\n","    input_mesh = np.column_stack((x_.ravel(), y_.ravel()))\n","    mean, std = opt.gp.predict(input_mesh, return_std=True)\n","\n","    z_predict = mean.reshape(x_.shape)\n","    c_predict = axs[1].contourf(x_, y_, z_predict, levels=100, cmap=\"viridis\")\n","    axs[1].set_title(\"Predict\")\n","    axs[1].grid()\n","    axs[1].plot()\n","\n","    if hasattr(opt, \"x_history\") and hasattr(opt, \"y_history\"):\n","        axs[1].scatter(opt.x_history[:opt.init, 0], opt.x_history[:opt.init, 1], c=\"black\", s=75, marker=\"+\")\n","        axs[1].scatter(opt.x_history[opt.init:, 0], opt.x_history[opt.init:, 1], c=\"blue\", s=75, marker=\"+\")\n","\n","\n","    diff = np.abs(z - z_predict)\n","    contour_diff = axs[2].contourf(x_, y_, diff, levels=100, cmap='coolwarm')\n","    axs[2].set_title(\"Actual - Predicted\")\n","    axs[2].grid()\n","    cbar_diff = fig.colorbar(contour_diff, ax=axs[2], orientation='vertical')\n","    # cbar_diff.set_label('')\n","\n","    fig.colorbar(c_actual, ax=[axs[0], axs[1]], orientation=\"horizontal\") \n","    plt.show()\n","\n","def kdeplot(y_true, y_pred):\n","    plt.figure(figsize=(24, 8))\n","    ax1 = sns.kdeplot(data=y_true, color=\"r\", label=\"Actual\")\n","    sns.kdeplot(data=y_pred, color=\"b\", label=\"Predicted\")\n","    ax1.set_title(\"Predicted VS Actual\")\n","    plt.legend()\n","    plt.show()\n","\n","def regplot(y_true, y_pred):\n","    plt.figure(figsize=(40, 25))\n","    ax = sns.regplot(x=y_true, y=y_pred)\n","    plt.title(\"Best Fit Line\")\n","    ax.set_xlabel(\"Actual\")\n","    ax.set_ylabel(\"Predicted\")\n","    plt.show()\n","\n","\n","\n","from matplotlib.animation import FuncAnimation\n","\n","class Result:\n","    def __init__(self, algo_name, func_name, best_sol, \n","                best_sol_decoded, best_fitness, params,\n","                fitness_history, pop_history) -> None:\n","        self.__algo_name = algo_name\n","        self.__func_namae = func_name\n","        self.x = best_sol\n","        self.x_decoded = best_sol_decoded\n","        self.fun = best_fitness\n","        self.__fitness_history = fitness_history\n","        self.__pop_history = pop_history\n","        self.__params = params\n","\n","    def res(self) -> pd.DataFrame:\n","        n_iter = self.__pop_history.shape[0]\n","        pop_decoded = []\n","        for idx in range(n_iter):\n","            for p in self.__pop_history[idx]:\n","                pop_decoded.append(convert_to_params(p, self.__params))\n","        \n","        fitness = self.__fitness_history.flatten()\n","        return pd.DataFrame(\n","            {\n","                **{k:[p[k] for p in pop_decoded] for k in self.__params},\n","                \"fitness\":fitness,\n","                \"iteration\":np.repeat(np.arange(0, n_iter), self.__pop_history.shape[1])\n","            }\n","        )\n","\n","    def func_name(self):\n","        return self.__func_namae\n","    \n","    def algo_name(self):\n","        return self.__algo_name\n","\n","    def fitness_history(self):\n","        return self.__fitness_history\n","    \n","    def population_history(self):\n","        return self.__pop_history\n","    \n","    def plot_fitness(self):\n","        fitness = np.min(self.__fitness_history, axis=1)\n","        plt.scatter([x for x in range(self.__fitness_history.shape[0])], fitness, marker=\"+\", c=\"black\", s=50)\n","        plt.plot([x for x in range(self.__fitness_history.shape[0])], fitness)\n","        plt.title(f\"Fitness Function : {self.__func_namae}\\nAlgorithm : {self.__algo_name}\")\n","        plt.xlabel(\"Iteration\")\n","        plt.ylabel(\"Fitness\")\n","        plt.grid()\n","        plt.show()\n","\n","    def plot_fitness_mean_bar(self):\n","        # for idx in range((self.__fitness_history.shape[0] )):\n","        #     plt.scatter([x for x in range(self.__fitness_history.shape[1])], self.__fitness_history[idx], marker=\"+\")\n","        mean = self.__fitness_history.mean(axis=1)\n","        plt.bar(x=[x for x in range(self.__fitness_history.shape[0])], height=mean)\n","        plt.title(\"Fitness Mean\")\n","        plt.style.use(\"seaborn-darkgrid\")\n","        plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Implement Acquisition Function"]},{"cell_type":"code","execution_count":140,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T00:20:20.757102Z","iopub.status.busy":"2024-05-24T00:20:20.756742Z","iopub.status.idle":"2024-05-24T00:20:20.767982Z","shell.execute_reply":"2024-05-24T00:20:20.766993Z","shell.execute_reply.started":"2024-05-24T00:20:20.757063Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting acquisition.py\n"]}],"source":["%%writefile acquisition.py\n","\n","from scipy.stats import norm\n","import numpy as np\n","\n","class AcqFunc:\n","\n","    def __init__(self, gp) -> None:\n","        self.__gp = gp\n","\n","    def func(self, X, kind:[\"ucb\", \"pi\", \"ei\", \"mix\"], **acq_params) -> callable:\n","\n","        if kind == \"ucb\":\n","            return self.GP_UCB(X, **acq_params)\n","        elif kind == \"lcb\":\n","            return self.GP_LCB(X, **acq_params)\n","        elif kind == \"ei\":\n","            return self.GP_EI(X, **acq_params)\n","        elif kind == \"pi\":\n","            return self.GP_PI(X, **acq_params)\n","        elif kind == \"mix\":\n","            pi = self.GP_PI(X, **acq_params)\n","            ei = self.GP_EI(X, **acq_params)\n","            ucb = self.GP_UCB(X, **acq_params)\n","            return (pi ** 2 + ei ** 2 + ucb ** 2) / pi + ei + ucb\n","        \n","    def GP_EI(self, X, xi=0.01, kappa=0, y_opt:float=0):\n","        mean, std = self.__gp.predict(X, return_std=True)\n","        values = np.zeros_like(mean)\n","        mask = std > 0\n","        improve = y_opt - xi - mean[mask]\n","        scaled = improve / std[mask]\n","        cdf = norm.cdf(scaled)\n","        pdf = norm.pdf(scaled)\n","        exploit = improve * cdf\n","        explore = std[mask] * pdf\n","        values[mask] = exploit + explore\n","        return values\n","\n","    def GP_PI(self, X, xi=0.01, kappa=0, y_opt:float=0):\n","        mean, std = self.__gp.predict(X, return_std=True)\n","        values = np.zeros_like(mean)\n","        mask = std > 0\n","        improve = y_opt - xi - mean[mask]\n","        scaled = improve / std[mask]\n","        values[mask] = norm.cdf(scaled)\n","        return values\n","\n","    def GP_UCB(self, X, xi=0, kappa=1.96, y_opt=0):\n","        mean, std = self.__gp.predict(X, return_std=True)\n","        return mean + kappa * std"]},{"cell_type":"markdown","metadata":{},"source":["# Implement base optimizer"]},{"cell_type":"code","execution_count":141,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T00:20:20.769860Z","iopub.status.busy":"2024-05-24T00:20:20.769494Z","iopub.status.idle":"2024-05-24T00:20:20.787948Z","shell.execute_reply":"2024-05-24T00:20:20.786849Z","shell.execute_reply.started":"2024-05-24T00:20:20.769833Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting optimizer.py\n"]}],"source":["%%writefile optimizer.py\n","import numpy as np\n","from abc import ABC, abstractmethod\n","from tqdm import tqdm\n","from util import Result\n","from paramsSpace import Real, Int, Cat, convert_to_bound, convert_to_params\n","import sys\n","\n","class Optimizer(ABC):\n","    def __init__(self, func, params,\n","                popsize, n_iter, ttl,\n","                verbose, random_state, checkpoint\n","                ) -> None:\n","        \n","        self.func = func\n","        self.params = params\n","        self.popsize = popsize\n","        self.n_iter = n_iter\n","        self.verbose = verbose\n","        self.ttl = ttl\n","        self.checkpoint = checkpoint\n","\n","        self.best_score = None\n","        self.best_params = None\n","        self.pbounds = None\n","        self.dimensions = len(self.params) if self.params is not None else None\n","\n","        # Seed the numpy first\n","        self.verify_random_state(random_state)\n","        if self.func is None and self.params is None:\n","            self.init_pop_fitness()\n","\n","\n","    @abstractmethod\n","    def optim(self):\n","        pass        \n","    \n","    def init_dimension(self):\n","        if \"x\" in self.params:\n","            self.dimensions = self.params[\"x\"].interval().shape[0]\n","        else:\n","            self.dimensions = len(self.params)\n","\n","    def preprocess(self):\n","        if \"x\" in self.params:\n","            mask_int = self.params[\"x\"].Int_idxs()\n","            mask_cat = self.params[\"x\"].Cat_idxs()\n","        else:\n","            mask_int = []\n","            mask_cat = []\n","            for idx, p in enumerate(self.params):\n","                if type(self.params[p]) == Int: \n","                    mask_int.append(idx)\n","                elif type(self.params[p]) == Cat:\n","                    mask_cat.append(idx)\n","            mask_int = np.array(mask_int)\n","            mask_cat = np.array(mask_cat)\n","        return mask_int, mask_cat\n","\n","    def init_pop_fitness(self):\n","        self.pop = np.zeros(shape=(self.popsize, self.dimensions))\n","        if \"x\" in self.params:\n","            self.pop = self.params[\"x\"].sample((self.popsize, self.dimensions))\n","        else:\n","            for idx, p in enumerate(self.params):\n","                self.pop[:, idx] = self.params[p].sample(shape=self.popsize)\n","        self.fitness = np.zeros((self.popsize, ))\n","        iteration = range(self.popsize)\n","\n","        if self.verbose:\n","            iteration = tqdm(iteration, desc=f\"Initializing {self.__class__.__name__}\")\n","        for idx, ind in zip(iteration, self.pop):      \n","            f = self.func(**convert_to_params(ind, self.params))\n","            self.fitness[idx] = f\n","\n","\n","    def set_func(self, func:callable):\n","        self.func = func\n","\n","\n","    def set_params(self, params:dict):\n","        self.params = params\n","\n","\n","    def verify_func_params(self):\n","        if self.func is None:\n","            ValueError(\"Please provide your function\")\n","        elif self.params is None:\n","            ValueError(\"Please provide you parameters\")\n","\n","    def verify_random_state(self, random_state):\n","        if isinstance(random_state, int):\n","            return np.random.seed(random_state)\n","        elif random_state is None:\n","            return np.random.seed(42)\n","        \n","class DifferentialEvol(Optimizer):\n","    def __init__(self, func:callable=None, params:dict=None, mut_1=0.9, mut_2=0.9, \n","                crossp=0.95, popsize=10, ttl=np.inf, checkpoint=3,\n","                n_iter=20, verbose=0, random_state=None) -> None:\n","        super().__init__(func, params, popsize, n_iter, ttl, verbose, random_state, checkpoint)\n","        self.mut_1 = mut_1\n","        self.mut_2 = mut_2\n","        self.crossp = crossp\n","\n","    def optim(self) -> Result:\n","        self.verify_func_params()\n","        self.init_dimension()\n","        self.init_pop_fitness()\n","        \n","        age = np.ones((self.popsize, )) * np.inf\n","        filename = \"DE\"\n","        if self.ttl > 0:\n","            age = np.ones((self.popsize, )) * self.ttl\n","            filename = \"ADE\"\n","\n","        mask_int, mask_cat = self.preprocess()\n","\n","        self.pbounds = convert_to_bound(self.params)\n","        min_b, max_b = self.pbounds.T\n","\n","        pop_history = np.zeros((self.n_iter + 1, self.popsize, self.dimensions))\n","        fitness_history = np.zeros((self.n_iter + 1, self.popsize))\n","        pop_history[0] = self.pop.copy()\n","        fitness_history[0] = self.fitness.copy()\n","\n","        best_idx = np.argmax(self.fitness)\n","        best_x = self.pop[best_idx]\n","        self.best_score = self.fitness[best_idx]\n","\n","\n","        for idx in range(self.n_iter):\n","            iteration = range(self.popsize)\n","            if self.verbose:\n","                iteration = tqdm(iteration, file=sys.stdout)\n","\n","            for jdx in iteration:\n","                age[jdx] -= 1\n","                if self.verbose:\n","                    iteration.set_description_str(desc=f\"Differential Evol {idx + 1}\")\n","                    iteration.set_postfix_str(f\"best_f : {round(self.best_score, 5)}\")\n","                idxs = [kdx for kdx in range(self.popsize) if kdx != jdx]\n","\n","                a, b, c = self.pop[np.random.choice(idxs, 3, replace = False)]\n","\n","                mutant = a + self.mut_1 * (b - c) + self.mut_2 * (best_x - a)\n","\n","                mutant[mutant > max_b] = max_b[mutant > max_b]\n","                mutant[mutant < min_b] = min_b[mutant < min_b]\n","\n","                cross_points = np.random.rand(self.dimensions) < self.crossp\n","                if not np.any(cross_points):\n","                    cross_points[np.random.randint(0, self.dimensions)] = True\n","                \n","                trial = np.where(cross_points, mutant, self.pop[jdx])\n","                # print(\"Trial before : \", trial)\n","                if mask_int.size:\n","                    trial[mask_int] = np.round(trial[mask_int])\n","                if mask_cat.size:\n","                    trial[mask_cat] = np.round(trial[mask_cat])\n","                # print(\"Trial after : \", trial)\n","                \n","                trial_ = convert_to_params(trial, self.params)\n","                f = self.func(**trial_)\n","                if f > self.fitness[jdx] or (age[jdx] == -1):\n","                    self.fitness[jdx] = f\n","                    self.pop[jdx] = trial\n","                    age[jdx] = self.ttl\n","                    if f > self.best_score:\n","                        best_x = trial\n","                        self.best_score = f\n","\n","            fitness_history[idx + 1] = self.fitness.copy()\n","            pop_history[idx + 1] = self.pop.copy()\n","            if self.checkpoint:\n","                if (idx > 0) and (idx % self.checkpoint == 0):\n","                    Result(self.__class__.__name__, self.func.__name__, \n","                        best_x, self.best_params, self.best_score, \n","                        self.params, fitness_history, pop_history).res().to_csv(f\"{filename}_{idx}.csv\", index=False)\n","\n","        self.best_params = convert_to_params(best_x, self.params)\n","        return Result(self.__class__.__name__, self.func.__name__, \n","                    best_x, self.best_params, self.best_score, \n","                    self.params, fitness_history, pop_history)\n","\n","class HarmonySearch(Optimizer):\n","    def __init__(self, func:callable=None, params:dict=None, HMCR=0.7, PAR=0.3, BW:np.array=None, \n","                 popsize=10, n_iter=20, ttl=np.inf, checkpoint=3,\n","                 verbose=0, random_state=None) -> None:\n","        super().__init__(func, params, popsize, n_iter, ttl, verbose, random_state, checkpoint)\n","        self.HMCR = HMCR\n","        self.PAR = PAR\n","        self.BW = BW\n","    \n","    def optim(self):\n","        self.verify_func_params()\n","        self.init_dimension()\n","        self.init_pop_fitness()\n","        \n","        age = np.ones((self.popsize, )) * np.inf\n","        filename = \"HS\"\n","        if self.ttl > 0:\n","            age = np.ones((self.popsize, )) * self.ttl\n","            filename = \"AHS\"\n","        \n","        mask_int, mask_cat = self.preprocess()\n","\n","        harmony_history = np.zeros((self.n_iter + 1, self.popsize, self.dimensions))\n","        fitness_history = np.zeros((self.n_iter + 1,self. popsize))\n","\n","        self.pbounds = convert_to_bound(self.params)\n","        min_b, max_b = self.pbounds.T\n","        diff = max_b - min_b\n","        if self.BW is not None:\n","            assert(self.BW.shape[0] == self.dimensions)\n","            diff = self.BW\n","\n","        harmony_history[0] = self.pop.copy()\n","        fitness_history[0] = self.fitness.copy()\n","        best_idx = np.argmax(self.fitness)\n","        worst_idx = np.argmin(self.fitness)\n","        best_harmony = self.pop[best_idx]\n","        self.best_score = self.fitness[best_idx]\n","\n","        for idx in range(self.n_iter):\n","            r1_ = np.random.rand(self.popsize, self.dimensions)\n","            r2_ = np.random.rand(self.popsize, self.dimensions)\n","            r3_ = np.random.uniform(low=-1, high=1.001, size=(self.popsize, self.dimensions))\n","            iteration = range(self.popsize)\n","            if self.verbose:\n","                iteration = tqdm(iteration, file=sys.stdout)\n","\n","            for jdx in iteration:\n","                age[jdx] -= 1\n","                if self.verbose:\n","                    iteration.set_description_str(desc=f\"Harmony Search {idx + 1}\")\n","                    iteration.set_postfix_str(f\"best_f : {round(self.best_score, 5)}\")\n","                trial = np.zeros(self.dimensions)\n","                for kdx in range(self.dimensions):\n","                    if r1_[jdx][kdx] < self.HMCR:\n","                        trial[kdx] = self.pop[np.random.randint(0, self.popsize)][kdx]\n","                    else:\n","                        trial[kdx] = np.random.uniform(min_b[kdx], max_b[kdx] + 0.001)\n","                    if r2_[jdx][kdx] < self.PAR:\n","                        trial[kdx] += r3_[jdx][kdx] * diff[kdx]\n","                trial[trial > max_b] = max_b[trial > max_b]\n","                trial[trial < min_b] = min_b[trial < min_b]\n","                if mask_int.size:\n","                    trial[mask_int] = np.round(trial[mask_int])\n","                if mask_cat.size:\n","                    trial[mask_cat] = np.round(trial[mask_cat])\n","\n","                trial_ = convert_to_params(trial, self.params)\n","                f = self.func(**trial_)\n","\n","                # Update worst_idx first and followed by best_idx\n","                # Ignore the trial harmony if worse than the worst harmont\n","                if (age[jdx] == -1):\n","                    self.pop[jdx] = trial\n","                    self.fitness[jdx] = f\n","                    age[jdx] = self.ttl\n","                elif f > self.fitness[worst_idx]:\n","                    self.pop[worst_idx] = trial\n","                    self.fitness[worst_idx] = f\n","                    age[jdx] = self.ttl\n","                    if f > self.best_score:\n","                        best_harmony = trial\n","                        self.best_score = f\n","                    worst_idx = np.argmin(self.fitness)\n","            fitness_history[idx + 1] = self.fitness.copy()\n","            harmony_history[idx + 1] = self.pop.copy()\n","            if self.checkpoint:\n","                if (idx > 0) and (idx % self.checkpoint == 0):\n","                    Result(self.__class__.__name__, self.func.__name__, \n","                        best_x, self.best_params, self.best_score, \n","                        self.params, fitness_history, pop_history).res().to_csv(f\"{filename}_{idx}.csv\", index=False)\n","\n","\n","        self.best_params = convert_to_params(best_harmony, self.params)\n","    \n","        return Result(self.__class__.__name__, self.func.__name__, \n","                      best_harmony, self.best_params, self.best_score, \n","                      self.params, fitness_history, harmony_history)\n","\n","class ParticleSwarm(Optimizer):\n","    def __init__(self, func:callable=None, params:dict=None, inertia=.5, cognitive=1.5, social=1.5, \n","                popsize=10, n_iter=20, ttl=np.inf, checkpoint=3,\n","                verbose=0, random_state=None) -> None:\n","        super().__init__(func, params, popsize, n_iter, ttl, verbose, random_state, checkpoint)\n","        self.inertia = inertia\n","        self.cognitive = cognitive\n","        self.social = social\n","\n","\n","    def optim(self) -> Result:\n","        self.verify_func_params()\n","        self.init_dimension()\n","        self.init_pop_fitness()\n","        \n","        age = np.ones((self.popsize, )) * np.inf\n","        filename = \"PSO\"\n","        if self.ttl > 0:\n","            age = np.ones((self.popsize, )) * self.ttl\n","            filename = \"APSO\"\n","        \n","        mask_int, mask_cat = self.preprocess()\n","\n","        swarm_history = np.zeros((self.n_iter + 1, self.popsize, self.dimensions))\n","        fitness_history = np.zeros((self.n_iter + 1, self.popsize))\n","\n","        self.pbounds = convert_to_bound(self.params)\n","        # print(bounds)\n","        min_b, max_b = self.pbounds.T\n","        diff = np.fabs(min_b - max_b)\n","\n","        swarm_history[0] = self.pop.copy()\n","        fitness_history[0] = self.fitness.copy()\n","        velocity = np.random.uniform(-np.abs(diff), np.abs(diff), (self.popsize, self.dimensions))\n","        swarm_best = self.pop.copy()\n","        best_idx = np.argmax(self.fitness)\n","        best_position = swarm_best[best_idx]\n","        self.best_score = self.fitness[best_idx]\n","\n","        for idx in range(self.n_iter):\n","            r_p = np.random.rand(self.popsize, self.dimensions)\n","            r_s = np.random.rand(self.popsize, self.dimensions)\n","            iteration = range(self.popsize)\n","            if self.verbose:\n","                iteration = tqdm(iteration, file=sys.stdout)\n","\n","            for jdx in iteration:\n","                age[jdx] -= 1\n","                if self.verbose:\n","                    iteration.set_description_str(f\"Swarm Particle {idx + 1}\")\n","                    iteration.set_postfix_str(f\"best_f : {round(self.best_score, 5)}\")\n","                velocity[jdx, :] = self.inertia * velocity[jdx, :] + self.cognitive * r_p[jdx, :] * (swarm_best[jdx, :] - self.pop[jdx, :]) + \\\n","                                            self.social * r_s[jdx, :] * (best_position - self.pop[jdx, :])\n","                self.pop[jdx, :] += velocity[jdx, :]\n","\n","                self.pop[jdx, self.pop[jdx, :] > max_b] = max_b[self.pop[jdx, :] > max_b]\n","                self.pop[jdx, self.pop[jdx, :] < min_b] = min_b[self.pop[jdx, :] < min_b]\n","                if mask_int.size:\n","                    self.pop[jdx][mask_int] = np.round(self.pop[jdx][mask_int])\n","                if mask_cat.size:\n","                    self.pop[jdx][mask_cat] = np.round(self.pop[jdx][mask_cat])\n","                trial_ = convert_to_params(self.pop[jdx], self.params)\n","                \n","                f = self.func(**trial_)\n","                if f > self.fitness[jdx] or (age[jdx] == -1):\n","                    swarm_best[jdx] = self.pop[jdx]\n","                    self.fitness[jdx] = f\n","                    age[jdx] = self.ttl\n","                    if f > self.best_score:\n","                        best_position = swarm_best[jdx]\n","                        self.best_score = f\n","            fitness_history[idx + 1] = self.fitness.copy()\n","            swarm_history[idx + 1] = self.pop.copy()\n","            if self.checkpoint:\n","                if (idx > 0) and (idx % self.checkpoint == 0):\n","                    Result(self.__class__.__name__, self.func.__name__, \n","                        best_x, self.best_params, self.best_score, \n","                        self.params, fitness_history, pop_history).res().to_csv(f\"{filename}_{idx}.csv\", index=False)\n","\n"," \n","\n","\n","        self.best_params = convert_to_params(best_position, self.params)\n","        return Result(self.__class__.__name__, self.func.__name__, \n","                      best_position, self.best_params, self.best_score, \n","                      self.params, fitness_history, swarm_history)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# Implement Bayesian Optimizer"]},{"cell_type":"code","execution_count":142,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-05-24T00:20:20.789760Z","iopub.status.busy":"2024-05-24T00:20:20.789426Z","iopub.status.idle":"2024-05-24T00:20:20.803194Z","shell.execute_reply":"2024-05-24T00:20:20.802242Z","shell.execute_reply.started":"2024-05-24T00:20:20.789727Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting bayesianOptimization.py\n"]}],"source":["%%writefile bayesianOptimization.py\n","\n","import acquisition as acqfunc, numpy as np\n","from scipy.optimize import minimize\n","from sklearn.gaussian_process import GaussianProcessRegressor\n","import pandas as pd\n","from paramsSpace import Real, Int, Cat, convert_to_bound, convert_to_params, AcqParams, decode_acq_params\n","from tqdm import tqdm\n","import optimizer\n","\n","class BayesianOptimizer:\n","    def __init__(self, f:callable=None, params=None, init_X=None, init_y=None, n_iter=10, n_init=5, \n","                kernel=None, verbose=0, random_state=None, checkpoint=20,\n","                **gp_params) -> None:\n","        self.f = f\n","        self.checkpoint = checkpoint\n","        self.__n_iter = n_iter\n","        self.init = n_init\n","        self.X_train = init_X\n","        self.y_train = init_y\n","        self.acq_history = []\n","        self.params = params\n","        self.random_state = random_state\n","        self.__verbose = verbose\n","        self.best_params:dict\n","\n","        if self.random_state is None:\n","            self.random_state = np.random.RandomState()\n","        elif isinstance(random_state, int):\n","            self.random_state = np.random.RandomState(random_state)\n","        else:\n","            assert isinstance(random_state, np.random.RandomState)\n","\n","\n","        if self.X_train is None and self.y_train is None and f is not None:\n","            self.X_train = np.zeros((n_init, len(params)))\n","            for idx, p in enumerate(params):\n","                self.X_train[:, idx] = params[p].sample(shape=n_init)\n","\n","            self.y_train = np.zeros((n_init, ))\n","\n","            iteration = range(self.X_train.shape[0])\n","            if verbose:\n","                iteration = tqdm(iteration, desc=f\"Initializing Bayesian Opt\")\n","            for idx in iteration:\n","                self.y_train[idx] = f(**(convert_to_params(self.X_train[idx], self.params)))                \n","            if self.y_train.ndim == 1:\n","                self.y_train = self.y_train.reshape(-1, 1)\n","        self.pbounds = convert_to_bound(params)\n","\n","\n","        self.gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, random_state=self.random_state, **gp_params)\n","        self.acqFunc = lambda x: acqfunc.AcqFunc(gp=self.gp).func(x.reshape(1, -1), \"ucb\", kappa=2.576)\n","\n","\n","    def set_f(self, f:callable, params:dict=None):\n","        if params is not None:\n","            self.params = params\n","            self.pbounds = convert_to_bound(params)     \n","        else:\n","            params = self.params\n","\n","        if self.X_train is None and self.y_train is None:\n","            self.X_train = np.zeros((self.init, len(params)))\n","            for idx, p in enumerate(params):\n","                self.X_train[:, idx] = params[p].sample(shape=self.init)\n","\n","            self.y_train = np.zeros((self.init, ))\n","\n","            iteration = range(self.X_train.shape[0])\n","            if self.__verbose:\n","                iteration = tqdm(iteration, desc=f\"Initializing Bayesian Opt\")\n","            for idx in iteration:\n","                self.y_train[idx] = f(**(convert_to_params(self.X_train[idx], self.params)))                \n","            if self.y_train.ndim == 1:\n","                self.y_train = self.y_train.reshape(-1, 1)\n","        self.f = f\n","\n","    def set_acqfunc(self, acqfunction:[\"ucb\", \"lcb\", \"pi\", \"ei\"]=\"ucb\", **acq_params):\n","        self.__acq_type = acqfunction\n","        self.__acq_params = acq_params\n","\n","    def optimize(self, opt=\"de\",  n_samples=25, **opt_params):\n","\n","        filename = f\"BO{opt.upper()}\"\n","        if \"ttl\" in opt_params:\n","            filename = \"BOA{opt.upper()}\"\n","\n","        params = {\n","            \"x\":AcqParams(self.params)\n","        }\n","\n","        iteration = range(self.__n_iter)\n","        if self.__verbose:\n","            iteration = tqdm(iteration, desc=\"Bayesian Optimization\")\n","\n","        for idx in iteration:\n","            if self.__verbose:\n","                iteration.set_postfix_str(f\"best_f : {round(self.y_train.max(), 5)}\")\n","            max_acq = -np.inf\n","            self.gp = self.gp.fit(self.X_train, self.y_train)\n","            self.acqFunc = lambda x: acqfunc.AcqFunc(gp=self.gp).func(x.reshape(1, -1), self.__acq_type, y_opt=self.y_train.max(), **self.__acq_params)\n","\n","    \n","                        \n","            if opt == \"de\":\n","                # print(\"DE Optimizer\")\n","                res = optimizer.DifferentialEvol(self.acqFunc, params, \n","                                        popsize=n_samples, checkpoint=False,\n","                                        random_state=self.random_state,\n","                                        **opt_params).optim()\n","            elif opt == \"hs\":\n","                # print(\"HS Optimizer\")\n","                res = optimizer.HarmonySearch(self.acqFunc, params,\n","                                        popsize=n_samples, checkpoint=False,\n","                                        random_state=self.random_state,\n","                                        **opt_params).optim()\n","            elif opt == \"pso\":\n","                # print(\"PSO Optimizer\")\n","                res = optimizer.ParticleSwarm(self.acqFunc, params, \n","                                        popsize=n_samples, checkpoint=False,\n","                                        random_state=self.random_state,\n","                                        **opt_params).optim()\n","            x_max = res.x\n","            x_max_encoded = res.x_decoded\n","            max_acq = res.fun\n","\n","            self.acq_history.append(max_acq.squeeze() if type(max_acq) == np.array else max_acq)\n","            self.X_train = np.vstack((self.X_train, [x_max]))\n","            self.y_train = np.vstack((self.y_train, [self.f(**decode_acq_params(x_max_encoded, self.params))]))\n","            if self.checkpoint:\n","                if (idx > 0) and (idx % self.checkpoint == 0):\n","                    self.res().to_csv(f\"{filename}_{idx}.csv\")\n","        best_idx = np.argmax(self.y_train)\n","        self.best_params = convert_to_params(self.X_train[best_idx], self.params)\n","\n","    def best_score(self):\n","        return np.max(self.y_train)\n","\n","    def best_params(self):\n","        return self.best_params\n","\n","    def res(self) -> pd.DataFrame:\n","        acq = [\"/\"] * self.init\n","        acq.extend(self.acq_history)\n","        col = list(self.params)\n","        decoded = []\n","        for x in self.X_train:\n","            decoded.append(convert_to_params(x, self.params))\n","        df = pd.DataFrame(\n","            {\n","                \"Acq\":acq,\n","                \"func\":self.y_train.flatten(),\n","                **{k:[p[k] for p in decoded] for k in self.params},\n","            }\n","        )\n","        return df"]},{"cell_type":"markdown","metadata":{},"source":["# Implement train, validation and test generator"]},{"cell_type":"code","execution_count":143,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T00:20:20.804866Z","iopub.status.busy":"2024-05-24T00:20:20.804505Z","iopub.status.idle":"2024-05-24T00:20:20.816707Z","shell.execute_reply":"2024-05-24T00:20:20.815770Z","shell.execute_reply.started":"2024-05-24T00:20:20.804828Z"},"trusted":true},"outputs":[],"source":["def initiateGenerator(path, batchSize, imageSize):\n","    base_path = path\n","    print(\"\\nTotal : \", end=\" \")\n","    train_dataset = tf.keras.preprocessing.image_dataset_from_directory(batch_size=batchSize, \n","                                                                        directory=base_path+\"/\"+\"train\")\n","    train_datagen = ImageDataGenerator(rescale=1./255)\n","\n","    print(\"\\nFor Training : \", end=\" \")\n","    train_generator = train_datagen.flow_from_directory(\n","        base_path+\"/\"+\"train\",\n","        target_size=(imageSize, imageSize),\n","        batch_size=batchSize,\n","        class_mode='categorical', subset='training')\n","\n","    print(\"\\nFor Val : \", end=\" \")\n","    valid_datagen = ImageDataGenerator(rescale=1./255)\n","    validation_generator = valid_datagen.flow_from_directory(\n","        base_path+\"/\"+\"valid\",\n","        target_size=(imageSize, imageSize),\n","        batch_size=batchSize,\n","        class_mode='categorical',shuffle=False)\n","    \n","    print(\"\\nFor Test : \", end=\" \")\n","    test_datagen = ImageDataGenerator(rescale=1./255)\n","    test_generator = test_datagen.flow_from_directory(\n","        base_path + \"/\" + \"test\",\n","        target_size=(imageSize, imageSize),\n","        batch_size=batchSize,\n","        class_mode='categorical', shuffle=False)\n","    class_names = train_dataset.class_names\n","    noOfClasses = len(class_names)\n","    print(\"\\nNo of Classes : \", noOfClasses)\n","    print(\"Classes : \", class_names)\n","\n","        \n","    return noOfClasses,class_names, train_generator, validation_generator, test_generator"]},{"cell_type":"code","execution_count":144,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T00:20:20.818413Z","iopub.status.busy":"2024-05-24T00:20:20.818113Z","iopub.status.idle":"2024-05-24T00:20:28.555838Z","shell.execute_reply":"2024-05-24T00:20:28.554691Z","shell.execute_reply.started":"2024-05-24T00:20:20.818388Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Total :  Found 3208 files belonging to 20 classes.\n","\n","For Training :  Found 3208 images belonging to 20 classes.\n","\n","For Val :  Found 100 images belonging to 20 classes.\n","\n","For Test :  Found 100 images belonging to 20 classes.\n","\n","No of Classes :  20\n","Classes :  ['ABBOTTS BABBLER', 'ABBOTTS BOOBY', 'ABYSSINIAN GROUND HORNBILL', 'AFRICAN CROWNED CRANE', 'AFRICAN EMERALD CUCKOO', 'AFRICAN FIREFINCH', 'AFRICAN OYSTER CATCHER', 'AFRICAN PIED HORNBILL', 'AFRICAN PYGMY GOOSE', 'ALBATROSS', 'ALBERTS TOWHEE', 'ALEXANDRINE PARAKEET', 'ALPINE CHOUGH', 'ALTAMIRA YELLOWTHROAT', 'AMERICAN AVOCET', 'AMERICAN BITTERN', 'AMERICAN COOT', 'AMERICAN FLAMINGO', 'AMERICAN GOLDFINCH', 'AMERICAN KESTREL']\n"]}],"source":["from paramsSpace import Int, Real, Cat\n","from bayesianOptimization import BayesianOptimizer\n","import optimizer\n","import tensorflow.keras.backend as K\n","from sklearn.gaussian_process import kernels\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import tensorflow as tf\n","from keras.preprocessing import image\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from keras import layers, models\n","from keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Rescaling, Conv2D, MaxPool2D, Dropout, Dense, Flatten, BatchNormalization\n","import numpy as np\n","from sklearn.utils import class_weight\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","imageSize = 64\n","batchSize = 32\n","epochs = 30\n","mpath = r\"/bird-species\"\n","\n","\n","noOfClasses, class_names, train_generator, validation_generator, test_generator = initiateGenerator(mpath, batchSize=batchSize, imageSize=imageSize)\n","INPUT_SHAPE = (imageSize, imageSize, 3)\n","KERNEL_SIZE = (3, 3)\n","class_weight = class_weight.compute_class_weight(\n","                class_weight='balanced',\n","                classes=np.unique(train_generator.classes), \n","                y=train_generator.classes)\n","class_weight = {x : class_weight[x] for x in range(len(class_weight))}\n"]},{"cell_type":"markdown","metadata":{},"source":["# Setup Base Model"]},{"cell_type":"code","execution_count":145,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T00:20:28.559329Z","iopub.status.busy":"2024-05-24T00:20:28.558953Z","iopub.status.idle":"2024-05-24T00:20:28.567235Z","shell.execute_reply":"2024-05-24T00:20:28.566170Z","shell.execute_reply.started":"2024-05-24T00:20:28.559291Z"},"trusted":true},"outputs":[],"source":["# record = []\n","# y_best = 0\n","# for idx in range(100):\n","#     annealer = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2, verbose=0, min_lr=1e-5, mode=\"max\")\n","#     early = EarlyStopping(monitor=\"val_accuracy\", patience=3, verbose=0, mode=\"max\")\n","#     model = Sequential()\n","\n","#     # Change Layer1\n","#     model.add(Conv2D(filters=32, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n","#     model.add(BatchNormalization())\n","    \n","#     # Change Layer2\n","#     model.add(Conv2D(filters=32, kernel_size=KERNEL_SIZE, activation='relu', padding='same'))\n","#     model.add(BatchNormalization())\n","    \n","#     model.add(MaxPool2D(pool_size=(2, 2)))\n","    \n","#     # Change Drop1\n","#     model.add(Dropout(0.25))\n","\n","#     # Change Layer3\n","#     model.add(Conv2D(filters=64, kernel_size=KERNEL_SIZE, activation='relu', padding='same'))\n","#     model.add(BatchNormalization())\n","    \n","#     # Change Layer4\n","#     model.add(Conv2D(filters=64, kernel_size=KERNEL_SIZE, activation='relu', padding='same'))\n","#     model.add(BatchNormalization())\n","    \n","#     model.add(MaxPool2D(pool_size=(2, 2)))\n","    \n","#     # Change Drop2\n","#     model.add(Dropout(0.25))\n","\n","#     # Change Layer5\n","#     model.add(Conv2D(filters=128, kernel_size=KERNEL_SIZE, activation='relu', padding='same'))\n","#     model.add(BatchNormalization())\n","    \n","#     # Change Layer6\n","#     model.add(Conv2D(filters=128, kernel_size=KERNEL_SIZE, activation='relu', padding='same'))\n","#     model.add(BatchNormalization())\n","    \n","#     model.add(MaxPool2D(pool_size=(2, 2)))\n","    \n","#     # Change Drop3\n","#     model.add(Dropout(0.25))\n","\n","#     model.add(Flatten())\n","\n","#     # Change Layer7\n","#     model.add(Dense(128, activation='relu'))\n","    \n","#     # Change Drop4\n","#     model.add(Dropout(0.25))\n","    \n","#     model.add(Dense(noOfClasses, activation='softmax'))\n","#     optimizer = tf.keras.optimizers.Adam(0.001)\n","#     # Change optimizer\n","#     model.compile(optimizer=optimizer,\n","#                   loss='categorical_crossentropy',\n","#                   metrics=['accuracy'])\n","\n","\n","#     # Train the model\n","#     model.fit(train_generator, epochs=epochs, \n","#             validation_data=validation_generator,\n","#             class_weight=class_weight,\n","#             callbacks=[annealer, early], verbose=0)\n","#     test_loss, test_acc = model.evaluate(test_generator)\n","#     record.append(test_acc)\n","        \n","# # Change the csv name\n","# pd.DataFrame({\"acc\":record}).to_csv(f\"Naive.csv\")"]},{"cell_type":"code","execution_count":146,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T00:20:28.568961Z","iopub.status.busy":"2024-05-24T00:20:28.568640Z","iopub.status.idle":"2024-05-24T00:20:29.413261Z","shell.execute_reply":"2024-05-24T00:20:29.412090Z","shell.execute_reply.started":"2024-05-24T00:20:28.568935Z"},"trusted":true},"outputs":[],"source":["params = {\n","    \"Layer1_filter\":Cat([32, 64]),\n","    \"Layer1_act\":Cat([\"relu\", \"selu\", \"elu\", \"leaky_relu\", \"gelu\"]),\n","    \"Layer2_filter\":Cat([32, 64]),\n","    \"Layer2_act\":Cat([\"relu\", \"selu\", \"elu\", \"leaky_relu\", \"gelu\"]),\n","\n","    \"Drop1\":Cat([0.25, 0.3, 0.35, 0.4, 0.45, 0.5]),\n","\n","    \"Layer3_filter\":Cat([32, 64, 128]),\n","    \"Layer3_act\":Cat([\"relu\", \"selu\", \"elu\", \"leaky_relu\", \"gelu\", \"relu6\"]),\n","    \"Layer4_filter\":Cat([32, 64, 128]),\n","    \"Layer4_act\":Cat([\"relu\", \"selu\", \"elu\", \"leaky_relu\", \"gelu\", \"relu6\"]),\n","    \n","    \"Drop2\":Cat([0.25, 0.3, 0.35, 0.4, 0.45, 0.5]),\n","\n","    \"Layer5_filter\":Cat([64, 128, 256]),\n","    \"Layer5_act\":Cat([\"relu\", \"selu\", \"elu\", \"leaky_relu\", \"gelu\", \"relu6\"]),\n","    \"Layer6_filter\":Cat([64, 128, 256]),\n","    \"Layer6_act\":Cat([\"relu\", \"selu\", \"elu\", \"leaky_relu\", \"gelu\", \"relu6\"]),\n","\n","    \"Drop3\":Cat([0.25, 0.3, 0.35, 0.4, 0.45, 0.5]),\n","\n","    \"Layer7_units\":Cat([128, 256, 512, 1024]),\n","    \"Layer7_act\":Cat([\"relu\", \"selu\", \"elu\", \"leaky_relu\", \"gelu\", \"relu6\"]),\n","    \n","    \"Drop4\":Cat([0.25, 0.3, 0.35, 0.4, 0.45, 0.5]),\n","\n","    \"optimizer\":Cat([\"adam\", \"nadam\", \"rmsprop\", \"sgd\", \"adagrad\", \"adadelta\"]),\n","    \"epochs\":Int(20, 50),\n","    \"batch_size\":Cat([8, 16, 32, 64]),\n","    \"learning_rate\":Real(0.001, 0.01) \n","}"]},{"cell_type":"markdown","metadata":{},"source":["# Blackbox Function"]},{"cell_type":"code","execution_count":147,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T00:20:29.415570Z","iopub.status.busy":"2024-05-24T00:20:29.415176Z","iopub.status.idle":"2024-05-24T00:20:29.438265Z","shell.execute_reply":"2024-05-24T00:20:29.437207Z","shell.execute_reply.started":"2024-05-24T00:20:29.415518Z"},"trusted":true},"outputs":[],"source":["def hyperTune(y_best=None, filename=\"\", **kwargs):\n","\n","    annealer = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2, verbose=0, min_lr=1e-5, mode=\"max\")\n","    early = EarlyStopping(monitor=\"val_accuracy\", patience=3, mode=\"max\", verbose=0)\n","    train_generator.batch_size = kwargs[\"batch_size\"]\n","    validation_generator.batch_size = kwargs[\"batch_size\"]\n","    test_generator.batch_size = kwargs[\"batch_size\"]\n","\n","    model = Sequential()\n","    model.add(Conv2D(filters=kwargs[\"Layer1_filter\"], kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation=kwargs[\"Layer1_act\"], padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(filters=kwargs[\"Layer2_filter\"], kernel_size=KERNEL_SIZE, activation=kwargs[\"Layer2_act\"], padding='same'))\n","    model.add(BatchNormalization())\n","    # Pooling layer\n","    model.add(MaxPool2D(pool_size=(2, 2)))\n","    # Dropout layers\n","    model.add(Dropout(kwargs[\"Drop1\"]))\n","\n","    model.add(Conv2D(filters=kwargs[\"Layer3_filter\"], kernel_size=KERNEL_SIZE, activation=kwargs[\"Layer3_act\"], padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(filters=kwargs[\"Layer4_filter\"], kernel_size=KERNEL_SIZE, activation=kwargs[\"Layer4_act\"], padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(MaxPool2D(pool_size=(2, 2)))\n","    model.add(Dropout(kwargs[\"Drop2\"]))\n","\n","    model.add(Conv2D(filters=kwargs[\"Layer5_filter\"], kernel_size=KERNEL_SIZE, activation=kwargs[\"Layer5_act\"], padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(filters=kwargs[\"Layer6_filter\"], kernel_size=KERNEL_SIZE, activation=kwargs[\"Layer6_act\"], padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(MaxPool2D(pool_size=(2, 2)))\n","    model.add(Dropout(kwargs[\"Drop3\"]))\n","\n","    model.add(Flatten())\n","    model.add(Dense(kwargs[\"Layer7_units\"], activation=kwargs[\"Layer7_act\"]))\n","    model.add(Dropout(kwargs[\"Drop4\"]))\n","    model.add(Dense(noOfClasses, activation='softmax'))\n","    if kwargs[\"optimizer\"] == \"sgd\":\n","        optimizer = tf.keras.optimizers.SGD(kwargs[\"learning_rate\"])\n","    elif kwargs[\"optimizer\"] == \"rmsprop\":\n","        optimizer = tf.keras.optimizers.RMSprop(kwargs[\"learning_rate\"])\n","    elif kwargs[\"optimizer\"] == \"adam\":\n","        optimizer = tf.keras.optimizers.Adam(kwargs[\"learning_rate\"])\n","    elif kwargs[\"optimizer\"] == \"nadam\":\n","        optimizer = tf.keras.optimizers.Nadam(kwargs[\"learning_rate\"])\n","    elif kwargs[\"optimizer\"] == \"adadelta\":\n","        optimizer = tf.keras.optimizers.Adadelta(kwargs[\"learning_rate\"])\n","    elif kwargs[\"optimizer\"] == \"adagrad\":\n","        optimizer = tf.keras.optimizers.Adagrad(kwargs[\"learning_rate\"])\n","    # Compile the model\n","    model.compile(optimizer=optimizer,\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","    # Train the model\n","    model.fit(train_generator, epochs=kwargs[\"epochs\"], \n","            class_weight=class_weight, verbose=0,\n","            validation_data=validation_generator,\n","            callbacks=[annealer, early])\n","\n","    test_loss, test_acc = model.evaluate(test_generator)\n","    del model\n","    return test_acc"]},{"cell_type":"markdown","metadata":{},"source":["# Setup Bayesian Optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T00:20:29.440009Z","iopub.status.busy":"2024-05-24T00:20:29.439697Z","iopub.status.idle":"2024-05-24T00:20:29.451909Z","shell.execute_reply":"2024-05-24T00:20:29.450884Z","shell.execute_reply.started":"2024-05-24T00:20:29.439983Z"},"trusted":true},"outputs":[],"source":["# np.random.seed(42)\n","# tf.random.set_seed(42)\n","# optim = BayesianOptimizer(\n","#     kernel=kernels.Matern(nu=2.5),\n","#     n_restarts_optimizer=5,\n","#     params=params,\n","#     n_iter=280,\n","#     n_init=20,\n","#     normalize_y=True,\n","#     verbose=1\n","# )\n","\n","# optim.set_f(lambda **x:hyperTune(optim.best_score(), \"byopt de\", **x))\n","# optim.set_acqfunc(acqfunction=\"mix\")\n","# optim.optimize(n_samples=50, \n","#                 opt=\"de\",\n","#                 n_iter=50,\n","#                 )\n","# print(\"BODE Result:\", optim.res())\n","# optim.res().to_csv(\"byopt de tuned.csv\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Initializing Bayesian Opt:   0%|          | 0/20 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 1s 98ms/step - loss: 0.9894 - accuracy: 0.7000\n"]},{"name":"stderr","output_type":"stream","text":["Initializing Bayesian Opt:   5%|▌         | 1/20 [01:12<22:49, 72.06s/it]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 21ms/step - loss: 3.2199 - accuracy: 0.0600\n"]},{"name":"stderr","output_type":"stream","text":["Initializing Bayesian Opt:  10%|█         | 2/20 [01:37<13:22, 44.57s/it]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 15ms/step - loss: 0.5474 - accuracy: 0.8200\n"]},{"name":"stderr","output_type":"stream","text":["Initializing Bayesian Opt:  15%|█▌        | 3/20 [02:18<12:07, 42.82s/it]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 11ms/step - loss: 2.7424 - accuracy: 0.2000\n"]},{"name":"stderr","output_type":"stream","text":["Initializing Bayesian Opt:  20%|██        | 4/20 [03:20<13:28, 50.54s/it]"]},{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 25ms/step - loss: 4.7061 - accuracy: 0.0600\n"]},{"name":"stderr","output_type":"stream","text":["Initializing Bayesian Opt:  25%|██▌       | 5/20 [03:41<10:00, 40.04s/it]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 9ms/step - loss: 1.9622 - accuracy: 0.3800\n"]},{"name":"stderr","output_type":"stream","text":["Initializing Bayesian Opt:  30%|███       | 6/20 [05:09<13:05, 56.11s/it]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 11ms/step - loss: 2.9322 - accuracy: 0.0800\n"]},{"name":"stderr","output_type":"stream","text":["Initializing Bayesian Opt:  35%|███▌      | 7/20 [05:45<10:43, 49.53s/it]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 28ms/step - loss: 0.6879 - accuracy: 0.7100\n"]},{"name":"stderr","output_type":"stream","text":["Initializing Bayesian Opt:  40%|████      | 8/20 [06:45<10:34, 52.85s/it]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 15ms/step - loss: 0.5257 - accuracy: 0.8500\n"]},{"name":"stderr","output_type":"stream","text":["Initializing Bayesian Opt:  45%|████▌     | 9/20 [08:35<13:00, 70.95s/it]"]},{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 27ms/step - loss: 7.4327 - accuracy: 0.0500\n"]},{"name":"stderr","output_type":"stream","text":["Initializing Bayesian Opt:  50%|█████     | 10/20 [08:57<09:17, 55.78s/it]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 29ms/step - loss: 0.8733 - accuracy: 0.6700\n"]},{"name":"stderr","output_type":"stream","text":["Initializing Bayesian Opt:  55%|█████▌    | 11/20 [09:57<08:34, 57.15s/it]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 11ms/step - loss: 0.6105 - accuracy: 0.8200\n"]},{"name":"stderr","output_type":"stream","text":["Initializing Bayesian Opt:  60%|██████    | 12/20 [11:54<10:01, 75.17s/it]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 18ms/step - loss: 2.2219 - accuracy: 0.3800\n"]},{"name":"stderr","output_type":"stream","text":["Initializing Bayesian Opt:  65%|██████▌   | 13/20 [14:06<10:46, 92.30s/it]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 25ms/step - loss: 0.8479 - accuracy: 0.6900\n"]},{"name":"stderr","output_type":"stream","text":["Initializing Bayesian Opt:  70%|███████   | 14/20 [14:47<07:41, 76.89s/it]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 17ms/step - loss: 2.7143 - accuracy: 0.1800\n"]},{"name":"stderr","output_type":"stream","text":["Initializing Bayesian Opt:  75%|███████▌  | 15/20 [15:18<05:15, 63.08s/it]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 27ms/step - loss: 0.8724 - accuracy: 0.7300\n"]},{"name":"stderr","output_type":"stream","text":["Initializing Bayesian Opt:  80%|████████  | 16/20 [16:27<04:19, 64.80s/it]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 16ms/step - loss: 2.8148 - accuracy: 0.1600\n"]},{"name":"stderr","output_type":"stream","text":["Initializing Bayesian Opt:  85%|████████▌ | 17/20 [17:09<02:53, 57.99s/it]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 10ms/step - loss: 0.6104 - accuracy: 0.7800\n"]},{"name":"stderr","output_type":"stream","text":["Initializing Bayesian Opt:  90%|█████████ | 18/20 [18:15<02:00, 60.44s/it]"]},{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 23ms/step - loss: 1.1489 - accuracy: 0.6300\n"]},{"name":"stderr","output_type":"stream","text":["Initializing Bayesian Opt:  95%|█████████▌| 19/20 [19:35<01:06, 66.45s/it]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 10ms/step - loss: 1.0192 - accuracy: 0.6700\n"]},{"name":"stderr","output_type":"stream","text":["Initializing Bayesian Opt: 100%|██████████| 20/20 [20:30<00:00, 61.53s/it]\n","Bayesian Optimization:   0%|          | 0/280 [00:00<?, ?it/s, best_f : 0.85]c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 10ms/step - loss: 2.9959 - accuracy: 0.0500\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   0%|          | 1/280 [00:45<3:32:40, 45.73s/it, best_f : 0.85]c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 10ms/step - loss: 3.4518 - accuracy: 0.0500\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   1%|          | 2/280 [01:14<2:45:00, 35.61s/it, best_f : 0.85]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 10ms/step - loss: 2.6972 - accuracy: 0.1300\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   1%|          | 3/280 [01:44<2:33:29, 33.25s/it, best_f : 0.85]c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 25ms/step - loss: 0.3566 - accuracy: 0.8800\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   1%|▏         | 4/280 [03:14<4:15:25, 55.53s/it, best_f : 0.88]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 26ms/step - loss: 1.4840 - accuracy: 0.5100\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   2%|▏         | 5/280 [04:43<5:10:01, 67.64s/it, best_f : 0.88]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 27ms/step - loss: 2.8789 - accuracy: 0.1500\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   2%|▏         | 6/280 [05:24<4:27:44, 58.63s/it, best_f : 0.88]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 9ms/step - loss: 0.4859 - accuracy: 0.8400\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   2%|▎         | 7/280 [07:27<6:02:09, 79.60s/it, best_f : 0.88]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 15ms/step - loss: 0.8120 - accuracy: 0.7000\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   3%|▎         | 8/280 [08:25<5:30:23, 72.88s/it, best_f : 0.88]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 16ms/step - loss: 3.0170 - accuracy: 0.0500\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   3%|▎         | 9/280 [08:48<4:18:52, 57.31s/it, best_f : 0.88]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 10ms/step - loss: 3.1916 - accuracy: 0.0500\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   4%|▎         | 10/280 [09:27<3:52:19, 51.63s/it, best_f : 0.88]c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 23ms/step - loss: 0.4289 - accuracy: 0.8900\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   4%|▍         | 11/280 [10:40<4:20:39, 58.14s/it, best_f : 0.89]"]},{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 23ms/step - loss: 1.4812 - accuracy: 0.5300\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   4%|▍         | 12/280 [12:07<4:58:36, 66.85s/it, best_f : 0.89]"]},{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 23ms/step - loss: 0.5668 - accuracy: 0.8100\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   5%|▍         | 13/280 [13:39<5:30:41, 74.31s/it, best_f : 0.89]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 23ms/step - loss: 3.0556 - accuracy: 0.1600\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   5%|▌         | 14/280 [14:18<4:43:25, 63.93s/it, best_f : 0.89]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 28ms/step - loss: 3.2353 - accuracy: 0.0500\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   5%|▌         | 15/280 [15:02<4:15:48, 57.92s/it, best_f : 0.89]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 10ms/step - loss: 0.7022 - accuracy: 0.8000\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   6%|▌         | 16/280 [18:00<6:53:40, 94.02s/it, best_f : 0.89]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 18ms/step - loss: 0.4607 - accuracy: 0.8300\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   6%|▌         | 17/280 [20:13<7:43:02, 105.64s/it, best_f : 0.89]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 27ms/step - loss: 0.5989 - accuracy: 0.7900\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   6%|▋         | 18/280 [21:11<6:38:51, 91.34s/it, best_f : 0.89] "]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 23ms/step - loss: 0.5812 - accuracy: 0.8100\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   7%|▋         | 19/280 [22:15<6:01:01, 83.00s/it, best_f : 0.89]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 27ms/step - loss: 1.4707 - accuracy: 0.5000\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   7%|▋         | 20/280 [23:37<5:58:33, 82.74s/it, best_f : 0.89]"]},{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 20ms/step - loss: 0.4446 - accuracy: 0.8500\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   8%|▊         | 21/280 [25:10<6:10:49, 85.90s/it, best_f : 0.89]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 12ms/step - loss: 0.3366 - accuracy: 0.9000\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   8%|▊         | 22/280 [27:46<7:40:27, 107.08s/it, best_f : 0.9] "]},{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 37ms/step - loss: 3.3344 - accuracy: 0.0700\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   8%|▊         | 23/280 [28:11<5:51:56, 82.17s/it, best_f : 0.9] "]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 11ms/step - loss: 0.5643 - accuracy: 0.8200\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   9%|▊         | 24/280 [30:13<6:42:47, 94.40s/it, best_f : 0.9]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 29ms/step - loss: 0.5429 - accuracy: 0.7800\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   9%|▉         | 25/280 [31:50<6:43:38, 94.97s/it, best_f : 0.9]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 11ms/step - loss: 2.8726 - accuracy: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:   9%|▉         | 26/280 [32:20<5:20:24, 75.69s/it, best_f : 0.9]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 26ms/step - loss: 0.7075 - accuracy: 0.7500\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  10%|▉         | 27/280 [33:45<5:29:58, 78.26s/it, best_f : 0.9]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 28ms/step - loss: 0.7444 - accuracy: 0.7200\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  10%|█         | 28/280 [34:43<5:03:09, 72.18s/it, best_f : 0.9]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 12ms/step - loss: 0.3309 - accuracy: 0.9100\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  10%|█         | 29/280 [38:09<7:49:54, 112.33s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 27ms/step - loss: 0.3908 - accuracy: 0.8700\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  11%|█         | 30/280 [39:54<7:39:36, 110.31s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 50ms/step - loss: 2.9636 - accuracy: 0.1100\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  11%|█         | 31/280 [40:25<5:58:30, 86.39s/it, best_f : 0.91] "]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 15ms/step - loss: 0.4986 - accuracy: 0.8000\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  11%|█▏        | 32/280 [42:53<7:13:58, 104.99s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 31ms/step - loss: 0.7357 - accuracy: 0.7700\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  12%|█▏        | 33/280 [44:39<7:13:34, 105.32s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 34ms/step - loss: 0.3732 - accuracy: 0.9100\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  12%|█▏        | 34/280 [46:00<6:41:10, 97.85s/it, best_f : 0.91] "]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 21ms/step - loss: 0.5221 - accuracy: 0.8100\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  12%|█▎        | 35/280 [47:16<6:12:52, 91.32s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 35ms/step - loss: 0.8432 - accuracy: 0.6900\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  13%|█▎        | 36/280 [48:12<5:28:06, 80.68s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 30ms/step - loss: 0.4408 - accuracy: 0.8400\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  13%|█▎        | 37/280 [49:38<5:33:50, 82.43s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 10ms/step - loss: 0.8746 - accuracy: 0.7300\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  14%|█▎        | 38/280 [52:59<7:55:11, 117.82s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 23ms/step - loss: 7.9795 - accuracy: 0.0500\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  14%|█▍        | 39/280 [53:27<6:05:33, 91.01s/it, best_f : 0.91] "]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 10ms/step - loss: 3.5871 - accuracy: 0.0500\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  14%|█▍        | 40/280 [54:06<5:02:01, 75.51s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 9ms/step - loss: 3.0691 - accuracy: 0.0500\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  15%|█▍        | 41/280 [54:57<4:30:22, 67.88s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 10ms/step - loss: 0.3150 - accuracy: 0.8700\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  15%|█▌        | 42/280 [57:10<5:46:56, 87.47s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 22ms/step - loss: 0.4149 - accuracy: 0.8700\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  15%|█▌        | 43/280 [58:27<5:33:21, 84.40s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 9ms/step - loss: 0.4133 - accuracy: 0.8600\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  16%|█▌        | 44/280 [1:01:18<7:14:26, 110.45s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 29ms/step - loss: 0.7781 - accuracy: 0.7200\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  16%|█▌        | 45/280 [1:02:02<5:54:36, 90.54s/it, best_f : 0.91] "]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 26ms/step - loss: 0.5401 - accuracy: 0.8400\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  16%|█▋        | 46/280 [1:03:14<5:30:49, 84.83s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 11ms/step - loss: 0.3831 - accuracy: 0.8700\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  17%|█▋        | 47/280 [1:05:50<6:52:22, 106.19s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 25ms/step - loss: 0.5678 - accuracy: 0.8100\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  17%|█▋        | 48/280 [1:07:39<6:54:01, 107.08s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 25ms/step - loss: 3.5293 - accuracy: 0.0500\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  18%|█▊        | 49/280 [1:07:59<5:11:55, 81.02s/it, best_f : 0.91] "]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 26ms/step - loss: 0.6725 - accuracy: 0.7700\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  18%|█▊        | 50/280 [1:09:20<5:10:30, 81.00s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 24ms/step - loss: 0.7119 - accuracy: 0.7300\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  18%|█▊        | 51/280 [1:10:54<5:24:00, 84.90s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 26ms/step - loss: 0.5967 - accuracy: 0.8000\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  19%|█▊        | 52/280 [1:12:06<5:08:05, 81.08s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 24ms/step - loss: 0.6952 - accuracy: 0.7800\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  19%|█▉        | 53/280 [1:13:04<4:40:19, 74.09s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 10ms/step - loss: 0.4363 - accuracy: 0.8300\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  19%|█▉        | 54/280 [1:15:19<5:47:36, 92.28s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 29ms/step - loss: 0.8487 - accuracy: 0.7000\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  20%|█▉        | 55/280 [1:16:27<5:18:41, 84.98s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 34ms/step - loss: 0.5191 - accuracy: 0.8600\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  20%|██        | 56/280 [1:17:51<5:16:19, 84.73s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 12ms/step - loss: 2.9315 - accuracy: 0.0700\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  20%|██        | 57/280 [1:18:19<4:12:19, 67.89s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 11ms/step - loss: 0.4489 - accuracy: 0.8400\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  21%|██        | 58/280 [1:20:14<5:03:25, 82.01s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 25ms/step - loss: 0.7351 - accuracy: 0.7500\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  21%|██        | 59/280 [1:20:56<4:17:11, 69.83s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 25ms/step - loss: 0.4185 - accuracy: 0.9000\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  21%|██▏       | 60/280 [1:22:32<4:45:08, 77.77s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 31ms/step - loss: 0.5654 - accuracy: 0.7900\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  22%|██▏       | 61/280 [1:24:01<4:55:41, 81.01s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 19ms/step - loss: 0.7570 - accuracy: 0.7800\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  22%|██▏       | 62/280 [1:25:04<4:35:20, 75.78s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 11ms/step - loss: 0.5842 - accuracy: 0.8100\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  22%|██▎       | 63/280 [1:26:16<4:29:29, 74.51s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 35ms/step - loss: 1.1440 - accuracy: 0.6200\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  23%|██▎       | 64/280 [1:27:39<4:37:42, 77.14s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 28ms/step - loss: 0.8045 - accuracy: 0.8100\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  23%|██▎       | 65/280 [1:28:45<4:24:20, 73.77s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 27ms/step - loss: 0.5491 - accuracy: 0.8300\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  24%|██▎       | 66/280 [1:29:56<4:19:55, 72.88s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 29ms/step - loss: 0.5309 - accuracy: 0.8600\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  24%|██▍       | 67/280 [1:31:15<4:25:42, 74.85s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 11ms/step - loss: 0.5255 - accuracy: 0.8000\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  24%|██▍       | 68/280 [1:33:08<5:04:16, 86.11s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 29ms/step - loss: 0.3987 - accuracy: 0.8900\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  25%|██▍       | 69/280 [1:34:11<4:38:29, 79.19s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 23ms/step - loss: 0.5457 - accuracy: 0.8000\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  25%|██▌       | 70/280 [1:35:20<4:27:03, 76.30s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 11ms/step - loss: 0.4335 - accuracy: 0.8600\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  25%|██▌       | 71/280 [1:38:08<6:01:49, 103.87s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 10ms/step - loss: 0.4439 - accuracy: 0.8400\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  26%|██▌       | 72/280 [1:40:25<6:33:50, 113.61s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 34ms/step - loss: 0.5221 - accuracy: 0.8600\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  26%|██▌       | 73/280 [1:41:59<6:11:46, 107.76s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 23ms/step - loss: 0.4930 - accuracy: 0.8400\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  26%|██▋       | 74/280 [1:43:49<6:12:32, 108.51s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 13ms/step - loss: 0.5215 - accuracy: 0.8100\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  27%|██▋       | 75/280 [1:46:20<6:53:54, 121.14s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 30ms/step - loss: 0.4866 - accuracy: 0.8400\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  27%|██▋       | 76/280 [1:48:00<6:30:46, 114.93s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 12ms/step - loss: 0.3569 - accuracy: 0.8600\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  28%|██▊       | 77/280 [1:49:50<6:23:30, 113.35s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 12ms/step - loss: 0.6582 - accuracy: 0.8000\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  28%|██▊       | 78/280 [1:51:27<6:05:41, 108.62s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 32ms/step - loss: 6.8816 - accuracy: 0.0500\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  28%|██▊       | 79/280 [1:52:01<4:48:06, 86.00s/it, best_f : 0.91] "]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 18ms/step - loss: 0.4631 - accuracy: 0.8700\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  29%|██▊       | 80/280 [1:53:18<4:38:21, 83.51s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 27ms/step - loss: 0.5529 - accuracy: 0.8100\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  29%|██▉       | 81/280 [1:54:30<4:24:50, 79.85s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 11ms/step - loss: 0.4446 - accuracy: 0.8300\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  29%|██▉       | 82/280 [1:56:37<5:09:59, 93.94s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 27ms/step - loss: 0.6058 - accuracy: 0.8200\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  30%|██▉       | 83/280 [1:57:36<4:34:19, 83.55s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 25ms/step - loss: 0.6012 - accuracy: 0.8300\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  30%|███       | 84/280 [1:59:04<4:37:10, 84.85s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 11ms/step - loss: 0.3183 - accuracy: 0.9000\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  30%|███       | 85/280 [2:01:24<5:29:39, 101.43s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 11ms/step - loss: 0.4938 - accuracy: 0.8400\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  31%|███       | 86/280 [2:02:41<5:04:54, 94.30s/it, best_f : 0.91] "]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 28ms/step - loss: 0.5429 - accuracy: 0.8000\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  31%|███       | 87/280 [2:04:15<5:02:07, 93.93s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 10ms/step - loss: 0.8053 - accuracy: 0.7600\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  31%|███▏      | 88/280 [2:06:01<5:12:25, 97.63s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 31ms/step - loss: 0.4364 - accuracy: 0.8800\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  32%|███▏      | 89/280 [2:07:23<4:56:23, 93.11s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 12ms/step - loss: 0.3905 - accuracy: 0.8700\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  32%|███▏      | 90/280 [2:09:25<5:22:17, 101.77s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 12ms/step - loss: 0.3004 - accuracy: 0.9000\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  32%|███▎      | 91/280 [2:11:49<5:59:50, 114.24s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 10ms/step - loss: 0.5145 - accuracy: 0.8500\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  33%|███▎      | 92/280 [2:13:31<5:46:49, 110.69s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 10ms/step - loss: 0.5025 - accuracy: 0.8300\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  33%|███▎      | 93/280 [2:15:18<5:41:15, 109.49s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 11ms/step - loss: 1.7600 - accuracy: 0.4400\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  34%|███▎      | 94/280 [2:16:59<5:31:19, 106.88s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 12ms/step - loss: 0.4910 - accuracy: 0.8100\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  34%|███▍      | 95/280 [2:18:36<5:21:05, 104.14s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 17ms/step - loss: 0.3369 - accuracy: 0.9100\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  34%|███▍      | 96/280 [2:19:42<4:43:31, 92.46s/it, best_f : 0.91] "]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 18ms/step - loss: 0.4464 - accuracy: 0.8500\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  35%|███▍      | 97/280 [2:22:47<6:06:47, 120.26s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 21ms/step - loss: 0.3013 - accuracy: 0.8900\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  35%|███▌      | 98/280 [2:25:08<6:23:57, 126.58s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 28ms/step - loss: 0.5471 - accuracy: 0.7600\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  35%|███▌      | 99/280 [2:26:20<5:32:05, 110.08s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 13ms/step - loss: 0.3304 - accuracy: 0.9000\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  36%|███▌      | 100/280 [2:28:43<6:00:29, 120.16s/it, best_f : 0.91]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 17ms/step - loss: 0.3007 - accuracy: 0.9300\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  36%|███▌      | 101/280 [2:30:56<6:09:20, 123.80s/it, best_f : 0.93]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 13ms/step - loss: 0.4985 - accuracy: 0.8200\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  36%|███▋      | 102/280 [2:34:51<7:46:20, 157.19s/it, best_f : 0.93]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 14ms/step - loss: 0.3673 - accuracy: 0.8900\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  37%|███▋      | 103/280 [2:36:46<7:07:00, 144.75s/it, best_f : 0.93]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 13ms/step - loss: 0.3778 - accuracy: 0.8900\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  37%|███▋      | 104/280 [2:38:51<6:46:57, 138.73s/it, best_f : 0.93]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 16ms/step - loss: 0.3722 - accuracy: 0.9000\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  38%|███▊      | 105/280 [2:40:53<6:29:42, 133.61s/it, best_f : 0.93]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 21ms/step - loss: 0.3045 - accuracy: 0.9000\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  38%|███▊      | 106/280 [2:42:37<6:02:17, 124.93s/it, best_f : 0.93]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 20ms/step - loss: 0.2760 - accuracy: 0.9500\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  38%|███▊      | 107/280 [2:45:26<6:37:49, 137.97s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 71ms/step - loss: 0.3864 - accuracy: 0.8900\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  39%|███▊      | 108/280 [2:46:53<5:51:51, 122.74s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 30ms/step - loss: 0.2390 - accuracy: 0.9200\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  39%|███▉      | 109/280 [2:49:01<5:54:16, 124.31s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 14ms/step - loss: 0.3233 - accuracy: 0.8700\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  39%|███▉      | 110/280 [2:50:53<5:41:33, 120.55s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 24ms/step - loss: 0.3026 - accuracy: 0.8900\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  40%|███▉      | 111/280 [2:52:28<5:17:59, 112.89s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 14ms/step - loss: 0.2997 - accuracy: 0.9000\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  40%|████      | 112/280 [2:54:08<5:05:34, 109.14s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 25ms/step - loss: 0.2858 - accuracy: 0.8900\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  40%|████      | 113/280 [2:55:41<4:50:19, 104.31s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 22ms/step - loss: 0.4943 - accuracy: 0.8300\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  41%|████      | 114/280 [2:56:39<4:10:24, 90.51s/it, best_f : 0.95] "]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 26ms/step - loss: 1.5939 - accuracy: 0.4300\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  41%|████      | 115/280 [2:58:16<4:14:07, 92.41s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 26ms/step - loss: 3.1291 - accuracy: 0.0500\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  41%|████▏     | 116/280 [2:58:44<3:19:29, 72.98s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 12ms/step - loss: 0.4534 - accuracy: 0.8800\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  42%|████▏     | 117/280 [3:00:02<3:22:16, 74.46s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 20ms/step - loss: 0.4201 - accuracy: 0.8600\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  42%|████▏     | 118/280 [3:00:52<3:01:16, 67.14s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 24ms/step - loss: 0.3211 - accuracy: 0.9000\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  42%|████▎     | 119/280 [3:02:30<3:25:24, 76.55s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 16ms/step - loss: 0.4234 - accuracy: 0.8500\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  43%|████▎     | 120/280 [3:04:12<3:44:19, 84.12s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 28ms/step - loss: 0.3178 - accuracy: 0.8400\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  43%|████▎     | 121/280 [3:05:41<3:46:26, 85.45s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 25ms/step - loss: 0.3103 - accuracy: 0.8800\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  44%|████▎     | 122/280 [3:07:41<4:12:32, 95.90s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 31ms/step - loss: 0.3136 - accuracy: 0.9200\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  44%|████▍     | 123/280 [3:09:30<4:20:57, 99.73s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 24ms/step - loss: 0.7741 - accuracy: 0.7600\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  44%|████▍     | 124/280 [3:15:26<7:39:31, 176.74s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 19ms/step - loss: 0.2329 - accuracy: 0.9400\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  45%|████▍     | 125/280 [3:16:59<6:31:22, 151.50s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 27ms/step - loss: 1.3468 - accuracy: 0.5600\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  45%|████▌     | 126/280 [3:19:33<6:30:52, 152.29s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 13ms/step - loss: 0.5181 - accuracy: 0.8300\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  45%|████▌     | 127/280 [3:21:27<5:59:22, 140.93s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 19ms/step - loss: 0.4134 - accuracy: 0.8300\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  46%|████▌     | 128/280 [3:22:35<5:01:29, 119.01s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 15ms/step - loss: 0.4608 - accuracy: 0.8700\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  46%|████▌     | 129/280 [3:24:00<4:33:34, 108.70s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 12ms/step - loss: 0.4381 - accuracy: 0.8500\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  46%|████▋     | 130/280 [3:25:33<4:20:10, 104.07s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 13ms/step - loss: 0.5606 - accuracy: 0.8400\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  47%|████▋     | 131/280 [3:26:57<4:03:12, 97.93s/it, best_f : 0.95] "]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 19ms/step - loss: 0.3481 - accuracy: 0.8800\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  47%|████▋     | 132/280 [3:28:02<3:37:32, 88.19s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 15ms/step - loss: 1.2756 - accuracy: 0.6400\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  48%|████▊     | 133/280 [3:31:34<5:06:40, 125.17s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 25ms/step - loss: 0.3659 - accuracy: 0.8300\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  48%|████▊     | 134/280 [3:32:51<4:29:53, 110.92s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 14ms/step - loss: 0.2417 - accuracy: 0.8900\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  48%|████▊     | 135/280 [3:34:42<4:27:51, 110.84s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 18ms/step - loss: 0.5157 - accuracy: 0.8200\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  49%|████▊     | 136/280 [3:36:15<4:13:00, 105.42s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 35ms/step - loss: 0.2506 - accuracy: 0.9300\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  49%|████▉     | 137/280 [3:37:26<3:47:02, 95.26s/it, best_f : 0.95] "]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 33ms/step - loss: 0.4525 - accuracy: 0.8900\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  49%|████▉     | 138/280 [3:39:09<3:50:58, 97.60s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 34ms/step - loss: 0.3173 - accuracy: 0.9000\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  50%|████▉     | 139/280 [3:40:51<3:52:23, 98.89s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 35ms/step - loss: 0.3295 - accuracy: 0.8900\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  50%|█████     | 140/280 [3:42:15<3:40:14, 94.39s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 24ms/step - loss: 0.2911 - accuracy: 0.9000\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  50%|█████     | 141/280 [3:43:23<3:20:20, 86.48s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 14ms/step - loss: 0.2818 - accuracy: 0.9000\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  51%|█████     | 142/280 [3:45:31<3:47:15, 98.81s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 50ms/step - loss: 0.3421 - accuracy: 0.8700\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  51%|█████     | 143/280 [3:46:56<3:36:03, 94.62s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 37ms/step - loss: 5.2851 - accuracy: 0.0500\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  51%|█████▏    | 144/280 [3:47:23<2:48:28, 74.33s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 10ms/step - loss: 0.4090 - accuracy: 0.8700\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  52%|█████▏    | 145/280 [3:48:52<2:57:13, 78.77s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 17ms/step - loss: 0.2094 - accuracy: 0.9000\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  52%|█████▏    | 146/280 [3:50:37<3:13:28, 86.63s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 10ms/step - loss: 0.4722 - accuracy: 0.8500\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  52%|█████▎    | 147/280 [3:53:01<3:50:25, 103.95s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 13ms/step - loss: 0.4465 - accuracy: 0.8400\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  53%|█████▎    | 148/280 [3:55:00<3:58:21, 108.35s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 11ms/step - loss: 0.6433 - accuracy: 0.7300\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  53%|█████▎    | 149/280 [3:55:58<3:23:52, 93.38s/it, best_f : 0.95] "]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 15ms/step - loss: 0.4306 - accuracy: 0.8600\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  54%|█████▎    | 150/280 [3:58:27<3:58:19, 110.00s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 20ms/step - loss: 0.7262 - accuracy: 0.7300\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  54%|█████▍    | 151/280 [3:59:28<3:24:43, 95.22s/it, best_f : 0.95] "]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 12ms/step - loss: 0.4185 - accuracy: 0.8700\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  54%|█████▍    | 152/280 [4:00:52<3:16:04, 91.91s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 20ms/step - loss: 0.4170 - accuracy: 0.8700\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  55%|█████▍    | 153/280 [4:02:30<3:18:37, 93.84s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 29ms/step - loss: 0.3211 - accuracy: 0.9000\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  55%|█████▌    | 154/280 [4:04:13<3:22:49, 96.58s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 20ms/step - loss: 0.3299 - accuracy: 0.8900\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  55%|█████▌    | 155/280 [4:05:55<3:24:17, 98.06s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 13ms/step - loss: 0.3873 - accuracy: 0.8800\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  56%|█████▌    | 156/280 [4:07:43<3:29:07, 101.19s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 11ms/step - loss: 0.3504 - accuracy: 0.8900\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  56%|█████▌    | 157/280 [4:09:39<3:36:31, 105.62s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 27ms/step - loss: 0.3341 - accuracy: 0.8800\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  56%|█████▋    | 158/280 [4:10:51<3:14:10, 95.50s/it, best_f : 0.95] "]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 11ms/step - loss: 1.1155 - accuracy: 0.6500\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  57%|█████▋    | 159/280 [4:12:31<3:15:16, 96.83s/it, best_f : 0.95]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 11ms/step - loss: 2.9960 - accuracy: 0.0500\n"]},{"name":"stderr","output_type":"stream","text":["Bayesian Optimization:  57%|█████▋    | 160/280 [4:13:43<3:10:17, 95.15s/it, best_f : 0.95]\n"]},{"ename":"ResourceExhaustedError","evalue":"Graph execution error:\n\nDetected at node 'Nadam/Nadam/update_24/truediv' defined at (most recent call last):\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_51352\\96571820.py\", line 14, in <module>\n      optim.optimize(n_samples=50,\n    File \"e:\\New folder\\bayesianOptimization.py\", line 125, in optimize\n      self.y_train = np.vstack((self.y_train, [self.f(**decode_acq_params(x_max_encoded, self.params))]))\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_51352\\96571820.py\", line 12, in <lambda>\n      optim.set_f(lambda **x:hyperTune(optim.best_score(), \"byopt pso\", **x))\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_51352\\4235481473.py\", line 54, in hyperTune\n      model.fit(train_generator, epochs=kwargs[\"epochs\"],\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 579, in minimize\n      return self.apply_gradients(grads_and_vars, name=name)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 738, in apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 797, in _distributed_apply\n      update_op = distribution.extended.update(\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 776, in apply_grad_to_update_var\n      update_op = self._resource_apply_dense(grad, var, **apply_kwargs)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\nadam.py\", line 170, in _resource_apply_dense\n      g_prime = grad / coefficients[\"one_minus_m_schedule_new\"]\nNode: 'Nadam/Nadam/update_24/truediv'\nfailed to allocate memory\n\t [[{{node Nadam/Nadam/update_24/truediv}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_20935153]","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","Cell \u001b[1;32mIn[87], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m optim\u001b[38;5;241m.\u001b[39mset_f(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mx:hyperTune(optim\u001b[38;5;241m.\u001b[39mbest_score(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbyopt pso\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mx))\n\u001b[0;32m     13\u001b[0m optim\u001b[38;5;241m.\u001b[39mset_acqfunc(acqfunction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpso\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m                \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBOPSO Result:\u001b[39m\u001b[38;5;124m\"\u001b[39m, optim\u001b[38;5;241m.\u001b[39mres())\n\u001b[0;32m     19\u001b[0m optim\u001b[38;5;241m.\u001b[39mres()\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbyopt pso tuned.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[1;32me:\\New folder\\bayesianOptimization.py:125\u001b[0m, in \u001b[0;36mBayesianOptimizer.optimize\u001b[1;34m(self, opt, n_samples, **opt_params)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macq_history\u001b[38;5;241m.\u001b[39mappend(max_acq\u001b[38;5;241m.\u001b[39msqueeze() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(max_acq) \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39marray \u001b[38;5;28;01melse\u001b[39;00m max_acq)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train, [x_max]))\n\u001b[1;32m--> 125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train, [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecode_acq_params(x_max_encoded, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams))]))\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint:\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (idx \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmod \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n","Cell \u001b[1;32mIn[87], line 12\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(**x)\u001b[0m\n\u001b[0;32m      2\u001b[0m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mset_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      3\u001b[0m optim \u001b[38;5;241m=\u001b[39m BayesianOptimizer(\n\u001b[0;32m      4\u001b[0m     kernel\u001b[38;5;241m=\u001b[39mkernels\u001b[38;5;241m.\u001b[39mMatern(nu\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.5\u001b[39m),\n\u001b[0;32m      5\u001b[0m     n_restarts_optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     11\u001b[0m )\n\u001b[1;32m---> 12\u001b[0m optim\u001b[38;5;241m.\u001b[39mset_f(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mx:hyperTune(optim\u001b[38;5;241m.\u001b[39mbest_score(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbyopt pso\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mx))\n\u001b[0;32m     13\u001b[0m optim\u001b[38;5;241m.\u001b[39mset_acqfunc(acqfunction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m optim\u001b[38;5;241m.\u001b[39moptimize(n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, \n\u001b[0;32m     15\u001b[0m                 opt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpso\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m                 n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     17\u001b[0m                 )\n","Cell \u001b[1;32mIn[85], line 54\u001b[0m, in \u001b[0;36mhyperTune\u001b[1;34m(y_best, filename, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     51\u001b[0m             loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     52\u001b[0m             metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mannealer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# print(\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m#     \"optim : \", kwargs[\"optimizer\"], \u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m#     \"lr : \", kwargs[\"learning_rate\"], \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m#     \"bs : \", train_generator.batch_size\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m#     )\u001b[39;00m\n\u001b[0;32m     69\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_generator)\n","File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'Nadam/Nadam/update_24/truediv' defined at (most recent call last):\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_51352\\96571820.py\", line 14, in <module>\n      optim.optimize(n_samples=50,\n    File \"e:\\New folder\\bayesianOptimization.py\", line 125, in optimize\n      self.y_train = np.vstack((self.y_train, [self.f(**decode_acq_params(x_max_encoded, self.params))]))\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_51352\\96571820.py\", line 12, in <lambda>\n      optim.set_f(lambda **x:hyperTune(optim.best_score(), \"byopt pso\", **x))\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_51352\\4235481473.py\", line 54, in hyperTune\n      model.fit(train_generator, epochs=kwargs[\"epochs\"],\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 579, in minimize\n      return self.apply_gradients(grads_and_vars, name=name)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 738, in apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 797, in _distributed_apply\n      update_op = distribution.extended.update(\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 776, in apply_grad_to_update_var\n      update_op = self._resource_apply_dense(grad, var, **apply_kwargs)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\nadam.py\", line 170, in _resource_apply_dense\n      g_prime = grad / coefficients[\"one_minus_m_schedule_new\"]\nNode: 'Nadam/Nadam/update_24/truediv'\nfailed to allocate memory\n\t [[{{node Nadam/Nadam/update_24/truediv}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_20935153]"]}],"source":["# np.random.seed(42)\n","# tf.random.set_seed(42)\n","# optim = BayesianOptimizer(\n","#     kernel=kernels.Matern(nu=2.5),\n","#     n_restarts_optimizer=5,\n","#     params=params,\n","#     n_iter=280,\n","#     n_init=20,\n","#     normalize_y=True,\n","#     verbose=1\n","# )\n","# optim.set_f(lambda **x:hyperTune(optim.best_score(), \"byopt pso\", **x))\n","# optim.set_acqfunc(acqfunction=\"mix\")\n","# optim.optimize(n_samples=50, \n","#                 opt=\"pso\",\n","#                 n_iter=50,\n","#                 )\n","# print(\"BOPSO Result:\", optim.res())\n","# optim.res().to_csv(\"byopt pso tuned.csv\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# np.random.seed(42)\n","# tf.random.set_seed(42)\n","# optim = BayesianOptimizer(\n","#     kernel=kernels.Matern(nu=2.5),\n","#     n_restarts_optimizer=5,\n","#     params=params,\n","#     n_iter=280,\n","#     n_init=20,\n","#     normalize_y=True,\n","#     verbose=1\n","# )\n","# optim.set_f(lambda **x:hyperTune(optim.best_score(), \"byopt hs\", **x))\n","# optim.set_acqfunc(acqfunction=\"mix\")\n","# optim.optimize(n_samples=50, \n","#                 opt=\"hs\",\n","#                 n_iter=50,\n","#                 )\n","# print(\"BOHS Result:\", optim.res())\n","# optim.res().to_csv(\"byopt hs tuned.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["# Setup Optimzier"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T00:20:29.454011Z","iopub.status.busy":"2024-05-24T00:20:29.453683Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Initializing DifferentialEvol:   0%|          | 0/20 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 13ms/step - loss: 0.7405 - accuracy: 0.7600\n"]},{"name":"stderr","output_type":"stream","text":["Initializing DifferentialEvol:   5%|▌         | 1/20 [01:11<22:36, 71.37s/it]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 14ms/step - loss: 2.1304 - accuracy: 0.3500\n"]},{"name":"stderr","output_type":"stream","text":["Initializing DifferentialEvol:  10%|█         | 2/20 [02:50<26:18, 87.71s/it]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 13ms/step - loss: 0.3494 - accuracy: 0.9100\n"]},{"name":"stderr","output_type":"stream","text":["Initializing DifferentialEvol:  15%|█▌        | 3/20 [04:12<24:07, 85.14s/it]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 8ms/step - loss: 2.3157 - accuracy: 0.3100\n"]},{"name":"stderr","output_type":"stream","text":["Initializing DifferentialEvol:  20%|██        | 4/20 [04:56<18:24, 69.04s/it]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 7ms/step - loss: 0.7336 - accuracy: 0.7400\n"]},{"name":"stderr","output_type":"stream","text":["Initializing DifferentialEvol:  25%|██▌       | 5/20 [06:27<19:09, 76.66s/it]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 7ms/step - loss: 2.1058 - accuracy: 0.3500\n"]},{"name":"stderr","output_type":"stream","text":["Initializing DifferentialEvol:  30%|███       | 6/20 [08:06<19:39, 84.29s/it]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 22ms/step - loss: 0.6836 - accuracy: 0.7900\n"]},{"name":"stderr","output_type":"stream","text":["Initializing DifferentialEvol:  35%|███▌      | 7/20 [09:27<18:03, 83.32s/it]"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 133ms/step - loss: 4.7167 - accuracy: 0.0500\n"]},{"name":"stderr","output_type":"stream","text":["Initializing DifferentialEvol:  40%|████      | 8/20 [09:45<12:30, 62.51s/it]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 13ms/step - loss: 0.4960 - accuracy: 0.8300\n"]},{"name":"stderr","output_type":"stream","text":["Initializing DifferentialEvol:  45%|████▌     | 9/20 [11:40<14:28, 78.98s/it]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 11ms/step - loss: 0.6331 - accuracy: 0.8000\n"]},{"name":"stderr","output_type":"stream","text":["Initializing DifferentialEvol:  50%|█████     | 10/20 [12:47<12:32, 75.21s/it]"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 19ms/step - loss: 0.6706 - accuracy: 0.7600\n"]},{"name":"stderr","output_type":"stream","text":["Initializing DifferentialEvol:  55%|█████▌    | 11/20 [13:27<09:40, 64.49s/it]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 11ms/step - loss: 0.3890 - accuracy: 0.8600\n"]},{"name":"stderr","output_type":"stream","text":["Initializing DifferentialEvol:  60%|██████    | 12/20 [14:36<08:47, 65.88s/it]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 7ms/step - loss: 2.0730 - accuracy: 0.4500\n"]},{"name":"stderr","output_type":"stream","text":["Initializing DifferentialEvol:  65%|██████▌   | 13/20 [16:13<08:47, 75.39s/it]"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 113ms/step - loss: 5.0622 - accuracy: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Initializing DifferentialEvol:  70%|███████   | 14/20 [16:32<05:48, 58.08s/it]"]},{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 19ms/step - loss: 0.2433 - accuracy: 0.9000\n"]},{"name":"stderr","output_type":"stream","text":["Initializing DifferentialEvol:  75%|███████▌  | 15/20 [17:58<05:33, 66.74s/it]"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 0s 12ms/step - loss: 0.6265 - accuracy: 0.7900\n"]},{"name":"stderr","output_type":"stream","text":["Initializing DifferentialEvol:  80%|████████  | 16/20 [19:14<04:37, 69.36s/it]"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 0s 8ms/step - loss: 2.6935 - accuracy: 0.1800\n"]},{"name":"stderr","output_type":"stream","text":["Initializing DifferentialEvol:  85%|████████▌ | 17/20 [20:30<03:34, 71.49s/it]"]},{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 21ms/step - loss: 4.4423 - accuracy: 0.0500\n"]},{"name":"stderr","output_type":"stream","text":["Initializing DifferentialEvol:  90%|█████████ | 18/20 [20:52<01:53, 56.54s/it]"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 136ms/step - loss: 3.9757 - accuracy: 0.0800\n"]},{"name":"stderr","output_type":"stream","text":["Initializing DifferentialEvol:  95%|█████████▌| 19/20 [21:25<00:49, 49.62s/it]"]},{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 22ms/step - loss: 6.9565 - accuracy: 0.0600\n"]},{"name":"stderr","output_type":"stream","text":["Initializing DifferentialEvol: 100%|██████████| 20/20 [21:41<00:00, 65.10s/it]\n"]},{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 24ms/step - loss: 0.3726 - accuracy: 0.8200\n","1/1 [==============================] - 0s 160ms/step - loss: 3.1956 - accuracy: 0.0500\n","4/4 [==============================] - 0s 21ms/step - loss: 0.3937 - accuracy: 0.8800\n","2/2 [==============================] - 0s 28ms/step - loss: 5.5796 - accuracy: 0.0500\n","13/13 [==============================] - 0s 10ms/step - loss: 2.2332 - accuracy: 0.3000\n","1/1 [==============================] - 0s 169ms/step - loss: 3.8601 - accuracy: 0.0500\n","13/13 [==============================] - 0s 10ms/step - loss: 0.4739 - accuracy: 0.8700\n","1/1 [==============================] - 0s 160ms/step - loss: 3.8193 - accuracy: 0.0700\n","7/7 [==============================] - 0s 21ms/step - loss: 1.5485 - accuracy: 0.4900\n","13/13 [==============================] - 0s 12ms/step - loss: 0.5799 - accuracy: 0.8000\n","13/13 [==============================] - 0s 12ms/step - loss: 0.4041 - accuracy: 0.8300\n","13/13 [==============================] - 0s 11ms/step - loss: 1.3944 - accuracy: 0.5500\n","1/1 [==============================] - 0s 184ms/step - loss: 4.0871 - accuracy: 0.0500\n","4/4 [==============================] - 0s 24ms/step - loss: 0.4145 - accuracy: 0.8500\n","4/4 [==============================] - 0s 27ms/step - loss: 2.0986 - accuracy: 0.8000\n","13/13 [==============================] - 0s 11ms/step - loss: 0.7082 - accuracy: 0.8100\n","13/13 [==============================] - 0s 10ms/step - loss: 1.4627 - accuracy: 0.5300\n","7/7 [==============================] - 0s 17ms/step - loss: 2.5827 - accuracy: 0.2500\n","13/13 [==============================] - 0s 7ms/step - loss: 0.5077 - accuracy: 0.8800\n","13/13 [==============================] - 0s 7ms/step - loss: 0.3585 - accuracy: 0.8400\n","Differential Evol 1: 100%|██████████| 20/20 [47:20<00:00, 142.03s/it, best_f : 0.91]\n","7/7 [==============================] - 0s 17ms/step - loss: 2.9966 - accuracy: 0.0500\n","7/7 [==============================] - 0s 12ms/step - loss: 0.5504 - accuracy: 0.7900\n","13/13 [==============================] - 0s 8ms/step - loss: 0.4831 - accuracy: 0.8300\n","7/7 [==============================] - 0s 14ms/step - loss: 0.5601 - accuracy: 0.8200\n","13/13 [==============================] - 0s 8ms/step - loss: 0.3809 - accuracy: 0.8700\n","4/4 [==============================] - 0s 19ms/step - loss: 0.7726 - accuracy: 0.8100\n","13/13 [==============================] - 0s 7ms/step - loss: 0.3864 - accuracy: 0.8900\n","2/2 [==============================] - 0s 19ms/step - loss: 0.6490 - accuracy: 0.8100\n","2/2 [==============================] - 0s 23ms/step - loss: 0.7434 - accuracy: 0.7400\n","7/7 [==============================] - 0s 12ms/step - loss: 2.7535 - accuracy: 0.1900\n","4/4 [==============================] - 0s 18ms/step - loss: 0.4392 - accuracy: 0.8400\n","4/4 [==============================] - 0s 19ms/step - loss: 0.3961 - accuracy: 0.8700\n","2/2 [==============================] - 0s 19ms/step - loss: 5.1198 - accuracy: 0.0500\n","2/2 [==============================] - 0s 20ms/step - loss: 0.7316 - accuracy: 0.7500\n","13/13 [==============================] - 0s 6ms/step - loss: 0.3324 - accuracy: 0.9100\n","7/7 [==============================] - 0s 11ms/step - loss: 2.7137 - accuracy: 0.2700\n","13/13 [==============================] - 0s 7ms/step - loss: 1.3918 - accuracy: 0.5500\n","13/13 [==============================] - 0s 8ms/step - loss: 0.4839 - accuracy: 0.8500\n","7/7 [==============================] - 0s 13ms/step - loss: 0.3443 - accuracy: 0.9100\n","7/7 [==============================] - 0s 14ms/step - loss: 0.5127 - accuracy: 0.8500\n","Differential Evol 2: 100%|██████████| 20/20 [1:19:19<00:00, 237.99s/it, best_f : 0.91]\n","7/7 [==============================] - 0s 13ms/step - loss: 2.7729 - accuracy: 0.1900\n","13/13 [==============================] - 0s 8ms/step - loss: 0.3824 - accuracy: 0.8700\n","4/4 [==============================] - 0s 20ms/step - loss: 0.4198 - accuracy: 0.8400\n","13/13 [==============================] - 0s 9ms/step - loss: 0.7242 - accuracy: 0.7800\n","4/4 [==============================] - 0s 19ms/step - loss: 0.6003 - accuracy: 0.7900\n","Differential Evol 3:  25%|██▌       | 5/20 [06:04<18:13, 72.92s/it, best_f : 0.91]\n"]},{"ename":"ResourceExhaustedError","evalue":"Graph execution error:\n\nDetected at node 'sequential_366/conv2d_2200/Conv2D' defined at (most recent call last):\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_51352\\3713705258.py\", line 8, in <module>\n      res = de_optimizer.optim()\n    File \"e:\\New folder\\optimizer.py\", line 162, in optim\n      f = self.func(**trial_)\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_51352\\3713705258.py\", line 7, in <lambda>\n      de_optimizer.set_func(lambda **x:hyperTune(de_optimizer.best_score, \"DE\", **x))\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_51352\\4235481473.py\", line 54, in hyperTune\n      model.fit(train_generator, epochs=kwargs[\"epochs\"],\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'sequential_366/conv2d_2200/Conv2D'\nOOM when allocating tensor with shape[128,256,16,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential_366/conv2d_2200/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_7367399]","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","Cell \u001b[1;32mIn[28], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m de_optimizer \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mDifferentialEvol(params\u001b[38;5;241m=\u001b[39mparams, popsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[0;32m      6\u001b[0m                                         ttl\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      7\u001b[0m de_optimizer\u001b[38;5;241m.\u001b[39mset_func(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mx:hyperTune(de_optimizer\u001b[38;5;241m.\u001b[39mbest_score, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mx))\n\u001b[1;32m----> 8\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mde_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAged DE Result:\u001b[39m\u001b[38;5;124m\"\u001b[39m, res\u001b[38;5;241m.\u001b[39mres())\n\u001b[0;32m     10\u001b[0m res\u001b[38;5;241m.\u001b[39mres()\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maged de tuned.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[1;32me:\\New folder\\optimizer.py:162\u001b[0m, in \u001b[0;36mDifferentialEvol.optim\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# print(\"Trial after : \", trial)\u001b[39;00m\n\u001b[0;32m    161\u001b[0m trial_ \u001b[38;5;241m=\u001b[39m convert_to_params(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m--> 162\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrial_)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness[jdx] \u001b[38;5;129;01mor\u001b[39;00m (age[jdx] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness[jdx] \u001b[38;5;241m=\u001b[39m f\n","Cell \u001b[1;32mIn[28], line 7\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(**x)\u001b[0m\n\u001b[0;32m      4\u001b[0m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mset_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      5\u001b[0m de_optimizer \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mDifferentialEvol(params\u001b[38;5;241m=\u001b[39mparams, popsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[0;32m      6\u001b[0m                                         ttl\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m de_optimizer\u001b[38;5;241m.\u001b[39mset_func(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mx:hyperTune(de_optimizer\u001b[38;5;241m.\u001b[39mbest_score, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mx))\n\u001b[0;32m      8\u001b[0m res \u001b[38;5;241m=\u001b[39m de_optimizer\u001b[38;5;241m.\u001b[39moptim()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAged DE Result:\u001b[39m\u001b[38;5;124m\"\u001b[39m, res\u001b[38;5;241m.\u001b[39mres())\n","Cell \u001b[1;32mIn[24], line 54\u001b[0m, in \u001b[0;36mhyperTune\u001b[1;34m(y_best, filename, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     51\u001b[0m             loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     52\u001b[0m             metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mannealer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# print(\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m#     \"optim : \", kwargs[\"optimizer\"], \u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m#     \"lr : \", kwargs[\"learning_rate\"], \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m#     \"bs : \", train_generator.batch_size\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m#     )\u001b[39;00m\n\u001b[0;32m     69\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_generator)\n","File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_366/conv2d_2200/Conv2D' defined at (most recent call last):\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_51352\\3713705258.py\", line 8, in <module>\n      res = de_optimizer.optim()\n    File \"e:\\New folder\\optimizer.py\", line 162, in optim\n      f = self.func(**trial_)\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_51352\\3713705258.py\", line 7, in <lambda>\n      de_optimizer.set_func(lambda **x:hyperTune(de_optimizer.best_score, \"DE\", **x))\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_51352\\4235481473.py\", line 54, in hyperTune\n      model.fit(train_generator, epochs=kwargs[\"epochs\"],\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'sequential_366/conv2d_2200/Conv2D'\nOOM when allocating tensor with shape[128,256,16,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential_366/conv2d_2200/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_7367399]"]}],"source":["# import optimizer\n","\n","# np.random.seed(42)\n","# tf.random.set_seed(42)\n","# de_optimizer = optimizer.DifferentialEvol(params=params, popsize=20, n_iter=15, verbose=1, \n","#                                         ttl=2)\n","# de_optimizer.set_func(lambda **x:hyperTune(de_optimizer.best_score, \"DE\", **x))\n","# res = de_optimizer.optim()\n","# print(\"Aged DE Result:\", res.res())\n","# res.res().to_csv(\"aged de tuned.csv\")\n","# print(de_optimizer.best_params)\n","# print(de_optimizer.best_score)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# np.random.seed(42)\n","# tf.random.set_seed(42)\n","# pso_optimizer = optimizer.ParticleSwarm(params=params, popsize=20, n_iter=15, verbose=1, \n","#                                         ttl=2)\n","# pso_optimizer.set_func(lambda **x:hyperTune(pso_optimizer.best_score, \"PSO\", **x))\n","# res = pso_optimizer.optim()\n","# print(\"Aged PSO Result:\", res.res())\n","# res.res().to_csv(\"aged pso tuned.csv\")\n","# print(pso_optimizer.best_params)\n","# print(pso_optimizer.best_score)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# np.random.seed(42)\n","# tf.random.set_seed(42)\n","# hs_optimizer = optimizer.HarmonySearch(params=params, popsize=20, n_iter=15, verbose=1, \n","#                                         ttl=2)\n","# hs_optimizer.set_func(lambda **x:hyperTune(hs_optimizer.best_score, \"HS\", **x))\n","# res = hs_optimizer.optim()\n","# print(\" Aged HS Result:\", res.res())\n","# res.res().to_csv(\"aged hs tuned.csv\")\n","# print(hs_optimizer.best_params)\n","# print(hs_optimizer.best_score)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# np.random.seed(42)\n","# tf.random.set_seed(42)\n","# de_optimizer = optimizer.DifferentialEvol(params=params, popsize=20, n_iter=15, verbose=1, \n","#                                         )\n","# de_optimizer.set_func(lambda **x:hyperTune(de_optimizer.best_score, \"DE\", **x))\n","# res = de_optimizer.optim()\n","# print(\"DE Result:\", res.res())\n","# res.res().to_csv(\"de tuned.csv\")\n","# print(de_optimizer.best_params)\n","# print(de_optimizer.best_score)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# np.random.seed(42)\n","# tf.random.set_seed(42)\n","# pso_optimizer = optimizer.ParticleSwarm(params=params, popsize=20, n_iter=15, verbose=1, \n","#                                         )\n","# pso_optimizer.set_func(lambda **x:hyperTune(pso_optimizer.best_score, \"PSO\", **x))\n","# res = pso_optimizer.optim()\n","# print(\"PSO Result:\", res.res())\n","# res.res().to_csv(\"pso tuned.csv\")\n","# print(pso_optimizer.best_params)\n","# print(pso_optimizer.best_score)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# np.random.seed(42)\n","# tf.random.set_seed(42)\n","# hs_optimizer = optimizer.HarmonySearch(params=params, popsize=20, n_iter=15, verbose=1, \n","#                                     )\n","# hs_optimizer.set_func(lambda **x:hyperTune(hs_optimizer.best_score, \"HS\", **x))\n","# res = hs_optimizer.optim()\n","# print(\"HS Result:\", res.res())\n","# res.res().to_csv(\"hs tuned.csv\")\n","# print(hs_optimizer.best_params)\n","# print(hs_optimizer.best_score)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":3093062,"sourceId":5324005,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
