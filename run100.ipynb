{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiateGenerator(path, batchSize, imageSize):\n",
    "    base_path = path\n",
    "    print(\"\\nTotal : \", end=\" \")\n",
    "    train_dataset = tf.keras.preprocessing.image_dataset_from_directory(batch_size=batchSize, \n",
    "                                                                        directory=base_path+\"/\"+\"train\")\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    print(\"\\nFor Training : \", end=\" \")\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        base_path+\"/\"+\"train\",\n",
    "        target_size=(imageSize, imageSize),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='categorical', subset='training')\n",
    "\n",
    "    print(\"\\nFor Val : \", end=\" \")\n",
    "    valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    validation_generator = valid_datagen.flow_from_directory(\n",
    "        base_path+\"/\"+\"valid\",\n",
    "#                 base_path+\"/\"+\"train\",\n",
    "\n",
    "#         base_path + \"/\" + \"Training\",\n",
    "        target_size=(imageSize, imageSize),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='categorical',shuffle=False)\n",
    "    \n",
    "    print(\"\\nFor Test : \", end=\" \")\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "#         base_path+\"/\"+\"Testing\",\n",
    "        base_path + \"/\" + \"test\",\n",
    "        target_size=(imageSize, imageSize),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='categorical', shuffle=False)\n",
    "    class_names = train_dataset.class_names\n",
    "    noOfClasses = len(class_names)\n",
    "    print(\"\\nNo of Classes : \", noOfClasses)\n",
    "    print(\"Classes : \", class_names)\n",
    "\n",
    "        \n",
    "    return noOfClasses,class_names, train_generator, validation_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total :  Found 3208 files belonging to 20 classes.\n",
      "\n",
      "For Training :  Found 3208 images belonging to 20 classes.\n",
      "\n",
      "For Val :  Found 100 images belonging to 20 classes.\n",
      "\n",
      "For Test :  Found 100 images belonging to 20 classes.\n",
      "\n",
      "No of Classes :  20\n",
      "Classes :  ['ABBOTTS BABBLER', 'ABBOTTS BOOBY', 'ABYSSINIAN GROUND HORNBILL', 'AFRICAN CROWNED CRANE', 'AFRICAN EMERALD CUCKOO', 'AFRICAN FIREFINCH', 'AFRICAN OYSTER CATCHER', 'AFRICAN PIED HORNBILL', 'AFRICAN PYGMY GOOSE', 'ALBATROSS', 'ALBERTS TOWHEE', 'ALEXANDRINE PARAKEET', 'ALPINE CHOUGH', 'ALTAMIRA YELLOWTHROAT', 'AMERICAN AVOCET', 'AMERICAN BITTERN', 'AMERICAN COOT', 'AMERICAN FLAMINGO', 'AMERICAN GOLDFINCH', 'AMERICAN KESTREL']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras import layers, models\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Rescaling, Conv2D, MaxPool2D, Dropout, Dense, Flatten, BatchNormalization\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "import pandas as pd\n",
    "\n",
    "imageSize = 64\n",
    "batchSize = 32\n",
    "mpath = r\"E:\\Downloads\\bird-species\"\n",
    "\n",
    "noOfClasses, class_names, train_generator, validation_generator, test_generator = initiateGenerator(mpath, batchSize=batchSize, imageSize=imageSize)\n",
    "INPUT_SHAPE = (imageSize, imageSize, 3)\n",
    "KERNEL_SIZE = (3, 3)\n",
    "class_weight = class_weight.compute_class_weight(\n",
    "                class_weight='balanced',\n",
    "                classes=np.unique(train_generator.classes), \n",
    "                y=train_generator.classes)\n",
    "class_weight = {x : class_weight[x] for x in range(len(class_weight))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperTune(**kwargs):\n",
    "\n",
    "    annealer = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2, verbose=0, min_lr=1e-5, mode=\"max\")\n",
    "    early = EarlyStopping(monitor=\"val_accuracy\", patience=3, mode=\"max\", verbose=0)\n",
    "    train_generator.batch_size = kwargs[\"batch_size\"]\n",
    "    validation_generator.batch_size = kwargs[\"batch_size\"]\n",
    "    test_generator.batch_size = kwargs[\"batch_size\"]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=kwargs[\"Layer1_filter\"], kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation=kwargs[\"Layer1_act\"], padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=kwargs[\"Layer2_filter\"], kernel_size=KERNEL_SIZE, activation=kwargs[\"Layer2_act\"], padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    # Pooling layer\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    # Dropout layers\n",
    "    model.add(Dropout(kwargs[\"Drop1\"]))\n",
    "\n",
    "    model.add(Conv2D(filters=kwargs[\"Layer3_filter\"], kernel_size=KERNEL_SIZE, activation=kwargs[\"Layer3_act\"], padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=kwargs[\"Layer4_filter\"], kernel_size=KERNEL_SIZE, activation=kwargs[\"Layer4_act\"], padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(kwargs[\"Drop2\"]))\n",
    "\n",
    "    model.add(Conv2D(filters=kwargs[\"Layer5_filter\"], kernel_size=KERNEL_SIZE, activation=kwargs[\"Layer5_act\"], padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=kwargs[\"Layer6_filter\"], kernel_size=KERNEL_SIZE, activation=kwargs[\"Layer6_act\"], padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(kwargs[\"Drop3\"]))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(kwargs[\"Layer7_units\"], activation=kwargs[\"Layer7_act\"]))\n",
    "    model.add(Dropout(kwargs[\"Drop4\"]))\n",
    "    model.add(Dense(noOfClasses, activation='softmax'))\n",
    "    if kwargs[\"optimizer\"] == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(kwargs[\"learning_rate\"])\n",
    "    elif kwargs[\"optimizer\"] == \"rmsprop\":\n",
    "        optimizer = tf.keras.optimizers.RMSprop(kwargs[\"learning_rate\"])\n",
    "    elif kwargs[\"optimizer\"] == \"adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(kwargs[\"learning_rate\"])\n",
    "    elif kwargs[\"optimizer\"] == \"nadam\":\n",
    "        optimizer = tf.keras.optimizers.Nadam(kwargs[\"learning_rate\"])\n",
    "    elif kwargs[\"optimizer\"] == \"adadelta\":\n",
    "        optimizer = tf.keras.optimizers.Adadelta(kwargs[\"learning_rate\"])\n",
    "    elif kwargs[\"optimizer\"] == \"adagrad\":\n",
    "        optimizer = tf.keras.optimizers.Adagrad(kwargs[\"learning_rate\"])\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    # Train the model\n",
    "    model.fit(train_generator, epochs=kwargs[\"epochs\"], \n",
    "            class_weight=class_weight, verbose=0,\n",
    "            validation_data=validation_generator,\n",
    "            callbacks=[annealer, early])\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(test_generator, verbose=0)\n",
    "    del model\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hyperparameters</th>\n",
       "      <th>BO + DE</th>\n",
       "      <th>BO + PSO</th>\n",
       "      <th>BO + HS</th>\n",
       "      <th>BO + ADE</th>\n",
       "      <th>BO + APSO</th>\n",
       "      <th>BO + AHS</th>\n",
       "      <th>DE</th>\n",
       "      <th>PSO</th>\n",
       "      <th>HS</th>\n",
       "      <th>ADE</th>\n",
       "      <th>APSO</th>\n",
       "      <th>AHS</th>\n",
       "      <th>Base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Layer1_filter</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Layer1_act</td>\n",
       "      <td>gelu</td>\n",
       "      <td>gelu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>selu</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>selu</td>\n",
       "      <td>relu</td>\n",
       "      <td>selu</td>\n",
       "      <td>selu</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Layer2_filter</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Layer2_act</td>\n",
       "      <td>elu</td>\n",
       "      <td>selu</td>\n",
       "      <td>elu</td>\n",
       "      <td>gelu</td>\n",
       "      <td>elu</td>\n",
       "      <td>gelu</td>\n",
       "      <td>elu</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>selu</td>\n",
       "      <td>gelu</td>\n",
       "      <td>elu</td>\n",
       "      <td>selu</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drop1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Layer3_filter</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Layer3_act</td>\n",
       "      <td>selu</td>\n",
       "      <td>selu</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>gelu</td>\n",
       "      <td>gelu</td>\n",
       "      <td>elu</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>selu</td>\n",
       "      <td>gelu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Layer4_filter</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Layer4_act</td>\n",
       "      <td>relu6</td>\n",
       "      <td>gelu</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>relu6</td>\n",
       "      <td>selu</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>gelu</td>\n",
       "      <td>relu6</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>elu</td>\n",
       "      <td>relu6</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Drop2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Layer5_filter</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Layer5_act</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu6</td>\n",
       "      <td>gelu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>relu6</td>\n",
       "      <td>elu</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>relu6</td>\n",
       "      <td>selu</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Layer6_filter</td>\n",
       "      <td>256</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>64</td>\n",
       "      <td>256</td>\n",
       "      <td>64</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Layer6_act</td>\n",
       "      <td>elu</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>elu</td>\n",
       "      <td>gelu</td>\n",
       "      <td>relu6</td>\n",
       "      <td>selu</td>\n",
       "      <td>selu</td>\n",
       "      <td>relu6</td>\n",
       "      <td>gelu</td>\n",
       "      <td>elu</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Drop3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Layer7_units</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Layer7_act</td>\n",
       "      <td>elu</td>\n",
       "      <td>selu</td>\n",
       "      <td>selu</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>selu</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>elu</td>\n",
       "      <td>relu</td>\n",
       "      <td>gelu</td>\n",
       "      <td>elu</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Drop4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>optimizer</td>\n",
       "      <td>sgd</td>\n",
       "      <td>nadam</td>\n",
       "      <td>nadam</td>\n",
       "      <td>adam</td>\n",
       "      <td>adam</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>adam</td>\n",
       "      <td>adam</td>\n",
       "      <td>sgd</td>\n",
       "      <td>adam</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>epochs</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>38</td>\n",
       "      <td>49</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>batch_size</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>learning_rate</td>\n",
       "      <td>0.008876</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.007374</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.007048</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.006352</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Mean Accuracy across 100 runs</td>\n",
       "      <td>0.8849</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.8491</td>\n",
       "      <td>0.8768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8717</td>\n",
       "      <td>0.8633</td>\n",
       "      <td>0.7811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Max Accuracy across 100 runs</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Min Accuracy across 100 runs</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Percentage of Improvement</td>\n",
       "      <td>13.288952</td>\n",
       "      <td>13.429779</td>\n",
       "      <td>8.705672</td>\n",
       "      <td>12.251953</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>15.183716</td>\n",
       "      <td>-100</td>\n",
       "      <td>11.599028</td>\n",
       "      <td>10.523621</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Hyperparameters    BO + DE    BO + PSO     BO + HS  \\\n",
       "0                   Layer1_filter         64          32          32   \n",
       "1                      Layer1_act       gelu        gelu        relu   \n",
       "2                   Layer2_filter         64          64          32   \n",
       "3                      Layer2_act        elu        selu         elu   \n",
       "4                           Drop1       0.25        0.35        0.45   \n",
       "5                   Layer3_filter         32          32          64   \n",
       "6                      Layer3_act       selu        selu  leaky_relu   \n",
       "7                   Layer4_filter         32         128          32   \n",
       "8                      Layer4_act      relu6        gelu  leaky_relu   \n",
       "9                           Drop2       0.25         0.4         0.3   \n",
       "10                  Layer5_filter        256         128         256   \n",
       "11                     Layer5_act       relu       relu6        gelu   \n",
       "12                  Layer6_filter        256          64          64   \n",
       "13                     Layer6_act        elu  leaky_relu  leaky_relu   \n",
       "14                          Drop3       0.25         0.5        0.35   \n",
       "15                   Layer7_units       1024         256         512   \n",
       "16                     Layer7_act        elu        selu        selu   \n",
       "17                          Drop4       0.25         0.5         0.4   \n",
       "18                      optimizer        sgd       nadam       nadam   \n",
       "19                         epochs         25          50          33   \n",
       "20                     batch_size         16           8          32   \n",
       "21                  learning_rate   0.008876    0.002288    0.007374   \n",
       "22                       Accuracy       0.94        0.93        0.91   \n",
       "23  Mean Accuracy across 100 runs     0.8849       0.886      0.8491   \n",
       "24   Max Accuracy across 100 runs       0.94        0.96        0.93   \n",
       "25   Min Accuracy across 100 runs       0.83        0.73        0.74   \n",
       "26      Percentage of Improvement  13.288952   13.429779    8.705672   \n",
       "\n",
       "      BO + ADE   BO + APSO    BO + AHS          DE         PSO          HS  \\\n",
       "0           32          32          64          64          32          64   \n",
       "1         relu        selu  leaky_relu  leaky_relu        relu        selu   \n",
       "2           32          32          32          32          64          64   \n",
       "3         gelu         elu        gelu         elu  leaky_relu        selu   \n",
       "4          0.5        0.35        0.45         0.5        0.45        0.25   \n",
       "5          128          32          64         128         128         128   \n",
       "6         relu  leaky_relu        gelu        gelu         elu  leaky_relu   \n",
       "7           64         128          32         128         128          64   \n",
       "8   leaky_relu       relu6        selu  leaky_relu        gelu       relu6   \n",
       "9         0.35        0.25        0.35        0.25        0.35         0.3   \n",
       "10         256         256         128          64         128         128   \n",
       "11         elu         elu  leaky_relu       relu6         elu  leaky_relu   \n",
       "12          64         256         128         256          64         256   \n",
       "13        relu         elu        gelu       relu6        selu        selu   \n",
       "14        0.25        0.25         0.3        0.25        0.35        0.45   \n",
       "15        1024        1024         512        1024         256         512   \n",
       "16  leaky_relu  leaky_relu        relu        selu  leaky_relu         elu   \n",
       "17         0.5        0.25        0.25         0.4        0.45        0.35   \n",
       "18        adam        adam     rmsprop        adam        adam         sgd   \n",
       "19          33          35          38          49          33          40   \n",
       "20           8           8          64          16           8           8   \n",
       "21    0.001089       0.001    0.001749       0.001    0.007048        0.01   \n",
       "22        0.93        0.93        0.91        0.94        0.91        0.94   \n",
       "23      0.8768         NaN         NaN         NaN         NaN      0.8997   \n",
       "24        0.94         NaN         NaN         NaN         NaN        0.96   \n",
       "25         0.8         NaN         NaN         NaN         NaN        0.83   \n",
       "26   12.251953        -100        -100        -100        -100   15.183716   \n",
       "\n",
       "           ADE       APSO         AHS    Base  \n",
       "0           64         32          32      32  \n",
       "1         relu       selu        selu    relu  \n",
       "2           32         64          64      32  \n",
       "3         gelu        elu        selu    relu  \n",
       "4         0.25        0.4        0.25    0.25  \n",
       "5          128         32          32      64  \n",
       "6         selu       gelu        relu    relu  \n",
       "7           32        128          32      64  \n",
       "8   leaky_relu        elu       relu6    relu  \n",
       "9         0.25       0.45        0.25    0.25  \n",
       "10          64         64          64     128  \n",
       "11       relu6       selu  leaky_relu    relu  \n",
       "12          64        256         256     128  \n",
       "13       relu6       gelu         elu    relu  \n",
       "14        0.25       0.35        0.45    0.25  \n",
       "15        1024       1024         512     128  \n",
       "16        relu       gelu         elu    relu  \n",
       "17         0.5        0.5        0.25    0.25  \n",
       "18        adam    adagrad     adagrad    adam  \n",
       "19          50         20          28      30  \n",
       "20          64          8           8      16  \n",
       "21       0.001   0.006352        0.01   0.001  \n",
       "22        0.94       0.96        0.93     NaN  \n",
       "23         NaN     0.8717      0.8633  0.7811  \n",
       "24         NaN       0.93        0.93    0.87  \n",
       "25         NaN       0.82        0.78     0.7  \n",
       "26        -100  11.599028   10.523621     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hp = pd.read_excel(r\"E:\\New folder\\best_hyperparameter.xls\")\n",
    "display(hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_algo = hp.columns[1:-1].to_list()\n",
    "hp_list = hp[\"Hyperparameters\"].to_list()[:-2]\n",
    "\n",
    "params = {}\n",
    "\n",
    "for algo in opt_algo:\n",
    "    hp_dict = {hp_list[idx]:idx for idx in range(len(hp_list))}\n",
    "    t = hp[algo][:-2].to_dict()\n",
    "    for idx, key in enumerate(hp_dict.keys()):\n",
    "        hp_dict[key] = t[idx]\n",
    "    params[algo] = hp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Algorithm :  ADE\n",
      "Hyperparameters :  {'Layer1_filter': 64, 'Layer1_act': 'relu', 'Layer2_filter': 32, 'Layer2_act': 'gelu', 'Drop1': 0.25, 'Layer3_filter': 128, 'Layer3_act': 'selu', 'Layer4_filter': 32, 'Layer4_act': 'leaky_relu', 'Drop2': 0.25, 'Layer5_filter': 64, 'Layer5_act': 'relu6', 'Layer6_filter': 64, 'Layer6_act': 'relu6', 'Drop3': 0.25, 'Layer7_units': 1024, 'Layer7_act': 'relu', 'Drop4': 0.5, 'optimizer': 'adam', 'epochs': 50, 'batch_size': 64, 'learning_rate': 0.001, 'Accuracy': 0.939999997615814, 'Mean Accuracy across 100 runs': nan, 'Max Accuracy across 100 runs': nan}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ADE:   1%|          | 1/100 [00:16<26:40, 16.16s/it, best_acc : 0.1] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10000000149011612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ADE:   2%|▏         | 2/100 [00:32<26:10, 16.03s/it, best_acc : 0.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07999999821186066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ADE:   3%|▎         | 3/100 [00:55<31:05, 19.23s/it, best_acc : 0.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07000000029802322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ADE:   4%|▍         | 4/100 [02:08<1:05:02, 40.65s/it, best_acc : 0.91]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9100000262260437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ADE:   5%|▌         | 5/100 [03:15<1:19:09, 50.00s/it, best_acc : 0.91]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8700000047683716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ADE:   5%|▌         | 5/100 [03:22<1:04:16, 40.59s/it, best_acc : 0.91]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m iteration:\n\u001b[0;32m     12\u001b[0m     iteration\u001b[38;5;241m.\u001b[39mset_postfix_str(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_acc : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(best_acc,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m5\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m     acc_ \u001b[38;5;241m=\u001b[39m hyperTune(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mv)\n\u001b[0;32m     15\u001b[0m     acc\u001b[38;5;241m.\u001b[39mappend(acc_)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(acc_)\n",
      "Cell \u001b[1;32mIn[40], line 54\u001b[0m, in \u001b[0;36mhyperTune\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     51\u001b[0m             loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     52\u001b[0m             metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mannealer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_generator, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1555\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m   1552\u001b[0m     data_handler\u001b[38;5;241m.\u001b[39m_initial_step \u001b[38;5;241m=\u001b[39m data_handler\u001b[38;5;241m.\u001b[39m_initial_step \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1553\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_load_initial_step_from_ckpt()\n\u001b[0;32m   1554\u001b[0m     )\n\u001b[1;32m-> 1555\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   1556\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m             epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m             _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m         ):\n\u001b[0;32m   1563\u001b[0m             callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\data_adapter.py:1374\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1373\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1374\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1375\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1376\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1377\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m original_spe\n\u001b[0;32m   1379\u001b[0m )\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    636\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    638\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    639\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "result = {}\n",
    "\n",
    "for algo, v in zip(opt_algo, params.values()):\n",
    "    print(\"Current Algorithm : \", algo)\n",
    "    print(\"Hyperparameters : \", v)\n",
    "    acc = []\n",
    "    iteration = tqdm.tqdm(range(100), desc=algo)\n",
    "    best_acc = -np.inf\n",
    "    for _ in iteration:\n",
    "        iteration.set_postfix_str(f\"best_acc : {round(best_acc, 5)}\")\n",
    "\n",
    "        acc_ = hyperTune(**v)\n",
    "        acc.append(acc_)\n",
    "        print(acc_)\n",
    "        if acc_ > best_acc:\n",
    "            best_acc = acc_\n",
    "\n",
    "    result[algo] = acc\n",
    "    pd.DataFrame({algo:acc}).to_csv(f\"{algo}.csv\", index=False)\n",
    "pd.DataFrame(result).to_csv(\"result.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
